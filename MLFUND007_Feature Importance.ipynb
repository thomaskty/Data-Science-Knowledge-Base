{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1cef1d-3d6f-4bbf-b135-a363ff1187ad",
   "metadata": {},
   "source": [
    "### Tree-based importance\n",
    "\n",
    "- impurity based feature importance\n",
    "- A feature is important if it is used often to split nodes and the split reduce uncertainty a lot.\n",
    "- Importance = How much total impurity this feature removes across the whole forest.\n",
    "- We have impurity measures like Gini, Entropy, Variance(MSE). We can compute the impurity difference between parent and child node. The impurity decrease is the value which is credited to the feature used in that split.\n",
    "- For a feature we can compute the the entire impurity reductions over the tree. And we can normalize it ( based on other feature’s importance)\n",
    "- If we have T trees then we can again take the sum and normalize it.\n",
    "\n",
    "$$\n",
    "\\text{Importance(f)} = \\sum_{s \\in S_f} \\Delta I_s\n",
    "$$\n",
    "\n",
    "Here $\\Delta_s$ is the impurity decrease at split s\n",
    "\n",
    "Following equation gives the feature importance in one tree; \n",
    "\n",
    "$$\n",
    "\\text{Normalized Importance(f)} = \\frac{\\text{Importance(f)}}{\\sum_j \\text{Importance(j)}}\n",
    "$$\n",
    "\n",
    "Now we have T trees ; \n",
    "\n",
    "$$\n",
    "\\text{Importance(f)} = \\frac{1}{T} \\sum_{t=1}^{T} \\text{Importance(f)}\n",
    "$$\n",
    "\n",
    "And after this we can normalize again to get the value between 0 and 1. \n",
    "\n",
    "- This approach is biased towards continuous variables.\n",
    "- High-cardinality categorical features.\n",
    "- If A and B are correlated ; Tree may pick only one. Other gets low importance even if its meaningful.\n",
    "\n",
    "### Permutation importance\n",
    "\n",
    "- Model agnostic, performance based\n",
    "- If feature is important, breaking its relationship with the target should hurt performance.\n",
    "- We do this by ;\n",
    "    - Randomly shuffling one feature column in the validation set.\n",
    "    - Keeping everything else the same\n",
    "    - Measuring how much the model performance drops\n",
    "    - Importance = Performance drop\n",
    "- Algorithm\n",
    "    - Train model on training set\n",
    "    - Evaluate on validation set - get $M_{\\text{base}}$\n",
    "    - For each feature j:\n",
    "        - Copy dataset\n",
    "        - Randomly permute column j in the validation set\n",
    "        - Predict with trained model\n",
    "        - Compute new performance $M_j$\n",
    "        - Importance = Difference from baseline\n",
    "    - Rank features by importance → Normalize\n",
    "    - We can use repeated permutations also and take the average for computing $M_j$\n",
    "- Issues\n",
    "    - If two features are correlated , shuffling one might not hurt much, because model can still use the other feature.\n",
    "\n",
    "### Linear model coefficients\n",
    "\n",
    "- In linear models, prediction is a weighted sum. Feature importance is based on the magnitude of the weight. But this is only meaningful after proper scaling.\n",
    "- In linear regression, increasing the $x_j$ by 1 unit changes the prediction by $w_j$ units.\n",
    "- In logistic regression increasing $x_j$ by 1 changes log-odds by $w_j$\n",
    "- Valid if all features are on same scale.\n",
    "- How strongly does this feature linearly change the model’s prediction\n",
    "- Not causal effect, Not nonlinear importance, Not interaction strength.\n",
    "\n",
    "### Drop-column\n",
    "\n",
    "- Leave-One-Feature-Out Method\n",
    "- If a feature is important, removing it entirely should hurt performance.\n",
    "- So we ;\n",
    "    - Train a model with all features\n",
    "    - Then remove one feature\n",
    "    - Retrain the model\n",
    "    - Compare performance\n",
    "- Issues;\n",
    "    - Correlated features can make issues\n",
    "    - Model changes after dropping\n",
    "\n",
    "### LIME\n",
    "\n",
    "- Local interpretable Model agnostic Explanations\n",
    "- Lime explains one prediction at a time by ;\n",
    "    - Creating fake data near that point ( perturbations) and weight by distance (using some distance kernel)\n",
    "    - Asking the black box model for predictions\n",
    "    - Fitting a simple model locally\n",
    "    - Using that simple model’s coefficient as feature importance.\n",
    "- Around this specific point, which features matter most?\n",
    "- Lime does not give global feature importance or overall model behavior\n",
    "- Problems with LIME\n",
    "    - Instability due to sampling → different explanations each run\n",
    "    - Choice of Kernel width\n",
    "    - Unrealistic perturbations\n",
    "\n",
    "### Partial Dependency Plot\n",
    "\n",
    "- Visual tools to understand how features affect predictions, especially for complex, black-box models\n",
    "- Shows the average effect of a feature on the model’s prediction, marginalising over all other features.\n",
    "- Algorithm\n",
    "    - Pick a feature $X_j$\n",
    "    - Choose a grid of values for this feature\n",
    "    - For each such value:\n",
    "        - Replace the feature with that value in all instances.\n",
    "        - Predict using the model\n",
    "        - Average predictions across all instances\n",
    "    - Plot average predictions over the selected grid of values\n",
    "- If we force feature $X_j = x$ for everyone, and let all other features vary as they normally do, what is the average predictions?\n",
    "- Shows overall relationship between feature and prediction\n",
    "- Is relationship increasing, decreasing nonlinear flat?\n",
    "- Model agnostic\n",
    "- Example : As age increases, predicted risk increases\n",
    "- Unrealistic data combinations\n",
    "\n",
    "### ICE - Individual Conditional Expectation Plot\n",
    "\n",
    "- Individual-level version of PDP\n",
    "- It shows one curve per data point\n",
    "- Algorithm\n",
    "    - Trained model\n",
    "    - Select a feature\n",
    "    - Choose some values for age\n",
    "    - Pick a line item ( sample)\n",
    "    - Create fake records for this sample ( based on the selected values)\n",
    "    - Get the prediction\n",
    "    - Draw the line for this sample\n",
    "    - Repeat this for many samples\n",
    "    - Each line shows how that particular feature affects the sample’s prediction\n",
    "    - Example : If everything about this person stayed the same except Age, what would the model do?\n",
    "- ICE = Sample wise effect : For this specific data point, how does changing this feature change the prediction?\n",
    "- PDP = Overall/Average Effect : On average across all data points, how does changing this feature change the prediction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e52f9-9d97-4313-a1e3-a8540b48f250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
