{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d2b893-78af-4272-8ab4-e99a18fc12f8",
   "metadata": {},
   "source": [
    "# Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef2c76-0c28-4ec1-b3f5-e3afdcc0d782",
   "metadata": {},
   "source": [
    "Consider a dataset with N examples, with each feature $x = (x_1,x_2, …, x_d)$ and output labels $y \\in \\Set{1,2,…,K}$ ( Classification ) and $y \\in \\mathcal{R}$  ( regression). The goal is to learn a function $f(x) → y$. \n",
    "\n",
    "Decision tree partitions the input space into rectangular regions and assigns a constant prediction to each region. Each split cuts the space into two ( or more ) parts. After many splits we will be having small regions. Inside each region, the model predicts ; the majority class for classification and mean value for regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace06b7-4a7d-4c02-bce1-0484e885044e",
   "metadata": {},
   "source": [
    "# What should be the split ?\n",
    "\n",
    "How does a tree decide where to split? A good split makes child nodes more ‘pure’. For classification we want the child node contains mostly one class and for regression we want values close to each other inside a child node. So to do this we need a measure of impurity. \n",
    "\n",
    "There are different choices for Impurity measures; \n",
    "\n",
    "$$\n",
    "\\text{Gini} = 1 - \\sum_{k=1}^{K}p_k^2\n",
    "$$\n",
    "\n",
    "- Gini = 0 when we have perfectly pure node\n",
    "- Gini is max when classes are evenly mixed - uniform distribution\n",
    "\n",
    "$$\n",
    "\\text{Entropy} = - \\sum_{k=1}^{K} p_k \\log_2 p_k\n",
    "$$\n",
    "\n",
    "- If all points belong to one class → No Uncertainty\n",
    "- If classes are evenly mixed → High Uncertainty\n",
    "\n",
    "$$\n",
    "\\text{Impurity after split} = \\frac{n_L}{n} I_L + \\frac{n_R}{n} I_R\n",
    "$$\n",
    "\n",
    "- $n_L$, $n_R$ : samples in left/right child\n",
    "- $I_L$, $I_R$ : impurities of children\n",
    "- We choose a split that minimizes this quantity.\n",
    "\n",
    "In Regression trees we the criteria is to minimize the variance/squared error; \n",
    "\n",
    "$$\n",
    "\\sum_{i \\in L}(y_i - \\bar{y}_L)^2 +\\sum_{i \\in R}(y_i - \\bar{y}_R)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\n",
    "$$\n",
    "\n",
    "- Each leaf predicts a constant\n",
    "- Best Constant = mean\n",
    "- Good split = groups with low spread\n",
    "\n",
    "We choose the `best(feature, threshold)` pair that yields max impurity reduction. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22dbad4-2f08-4c4a-907d-cea0fb23c061",
   "metadata": {},
   "source": [
    "# CART Algorithm\n",
    "\n",
    "CART stands for classification and regression trees - it’s the algorithm scikit-learn implements in both `DecisionTreeClassifier` and `DecisionTreeRegressor` \n",
    "\n",
    "- Uses binary splits, even for nominal data\n",
    "- For classification, impurity is measured by Gini/Gain\n",
    "- For regression, impurity is MSE ( Mean Squared Error)\n",
    "- Always seeks the best split over candidate thresholds\n",
    "- In CART algorithm we have pre-pruning only (usually)\n",
    "\n",
    "This is not ID3 or C4.5 exactly - CART is similar to C4.5 but specialized for binary splits and regression as well. \n",
    "\n",
    "For continuous data we use finite splits. The training dataset only has a finite number of values per feature. So the algorithm; \n",
    "\n",
    "- Sorts the feature values seen at the current node\n",
    "- Consider candidate thresholds only between adjacent sorted values.\n",
    "\n",
    "$$\n",
    "t_i = \\frac{v_i+v_{i+1}}{2}\n",
    "$$\n",
    "\n",
    "- Evaluates each threshold by computing impurity before & after split\n",
    "- Search is finite and efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0468baf-e86e-4847-9b5d-77f525f59076",
   "metadata": {},
   "source": [
    "# Encoding Categorical\n",
    "\n",
    "Because scikit-learn cannot natively split categorical variables, practitioners encode them first; \n",
    "\n",
    "- One-hot encoding : turns a categorical variable with many levels into binary columns\n",
    "- Ordinal Encoding - sometimes okay for ordinal categories ( like low-medium-high) but be careful if order isn’t meaningful.\n",
    "- This is why libraries like LightGBM or CatBoost add special categorical handling - but scikit-learn doesn’t yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd190613-d4d7-4b8b-bb37-8bb2c3db98db",
   "metadata": {},
   "source": [
    "# Stopping Criteria ( Why Trees Overfit )\n",
    "\n",
    "If you let the tree grow ; it can memorize the data → Zero training error → Terrible generalization. So we have some common stopping rules : `max_depth` , `min_samples_split` , `min_samples_leaf`, `min_impurity_decrease` \n",
    "\n",
    "Each split increases model flexibility\n",
    "\n",
    "$$\n",
    "O(d * N \\log N)\n",
    "$$\n",
    "\n",
    "d is the feature dimension, N is the total number of samples. In prediction we have 0(depth) of complexity. \n",
    "\n",
    "# Merits of Decision Trees\n",
    "\n",
    "- Interpretable model\n",
    "- Handles Nonlinearity\n",
    "- No feature Scaling\n",
    "- Handles mixed data types ( Not in sklearn)\n",
    "- Fast Inference\n",
    "\n",
    "# Demerits of Decision Trees\n",
    "\n",
    "- High Variance (Highly flexible Model)\n",
    "- Unstable ( Small data change → Different Tree)\n",
    "- Greedy suboptimal splits\n",
    "- Axis-Aligned Splits Only\n",
    "- Poor Extrapolation\n",
    "\n",
    "# Properties of Decision Trees\n",
    "\n",
    "- Trees are piecewise constant → Within each region, prediction does not change\n",
    "- Trees approximate functions using rectangles → Each R_m is an axis-aligned box\n",
    "- Trees cannot extrapolate → Outside training regions, prediction is still a constant\n",
    "- Trees are not smooth → No continuity, no gradients\n",
    "\n",
    "# Pre-Pruning Decision Trees\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\Set{(x_i,y_i)}_{i=1}^{N}\\end{align*}\n",
    "$$\n",
    "\n",
    "We want a prediction function $\\hat{f_T}(x)$. For a tree T, define training error as ; \n",
    "\n",
    "$$\n",
    "R(T) = \\frac{1}{N} \\sum_{i=1}^{N} L(y_i, \\hat{f}_T(x_i))\n",
    "$$\n",
    "\n",
    "For classification → Misclassification loss / Gini Proxy \n",
    "\n",
    "For regression → Squared error\n",
    "\n",
    "This is how well the tree fits training data. \n",
    "\n",
    "$$\n",
    "\\min_T R(T) \\quad \\text{subject to constraints}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\Delta I &\\ge \\epsilon\\\\ |S_{node}| & \\ge k \\\\ \\text{depth(T)} &\\le D \\end{align*}\n",
    "$$\n",
    "\n",
    "These constraints prevent splits from ever being considered. Pre-pruning restricts the hypothesis space before optimization. It does not change the loss function - it changes what trees are allowed. Because decision trees are greedy; A split that looks weak now might enable strong future splits. Pre-pruning may block those future improvements. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec58537-6c92-4470-830a-5725acf12c82",
   "metadata": {},
   "source": [
    "# Cost - Complexity Pruning ( Post-Pruning)\n",
    "\n",
    "CART defines a regularised objective; \n",
    "\n",
    "$$\n",
    "R_\\alpha(T) = R(T) + \\alpha |T|\n",
    "$$\n",
    "\n",
    "$R(T)$ = Training Error ( data fit) \n",
    "\n",
    "$|T|$ = Number of leaf nodes ( Model complexity) \n",
    "\n",
    "$\\alpha \\ge 0$ = Complexity penalty ( How much we penalize complexity ) \n",
    "\n",
    "The optimal tree is the one that minimizes this quantity. \n",
    "\n",
    "- Different alpha values prefer different tree sizes\n",
    "- Small alpha → complex trees allowed\n",
    "- Large alpha → Simple trees preferred.\n",
    "\n",
    "This is regularisation, exactly like L1/L2 - but for trees. \n",
    "\n",
    "$$\n",
    "T^*(\\alpha) = \\arg\\min_{T \\subseteq T_0} R_\\alpha(T)\n",
    "$$\n",
    "\n",
    "Among all subtrees of the full tree, we choose the one that minimizes penalized risk. CART does not try all subtrees ( too many). Instead it proves that only a finite sequence of candidate trees can be optimal. These trees form a nested sequence\n",
    "\n",
    "$T_0⊃T_1⊃T_2⊃⋯⊃T_K$\n",
    "\n",
    "Each step removes the weakest link; What is a weakest link? \n",
    "\n",
    "For an internal node t; \n",
    "\n",
    "$$\n",
    "\\alpha_t = \\frac{R(t) - R(T_t)}{|T_t| - 1}\n",
    "$$\n",
    "\n",
    "$T_t$ is the entire subtree rooted at $t$. So t is the root of that subtree. $T_t$  includes - node $t$, all its descendants and all leaf nodes under it. and Now $|T_t|$ is the number of lead nodes in the subtree $T_t.$ Why leaves? Each leaf corresponds to one region $R_m$. Each leaf adds one constant prediction. Leaves measure model complexity. \n",
    "\n",
    "- Pruning at t reduces the model complexity by $|T_t| - 1$ leaves.\n",
    "- $R(T_t)$ - Training error of the entire subtree. Sum of losses over all leaves under t.\n",
    "- $R(t)$ - Training error if we collapse the subtree into a single leaf.\n",
    "- The numerator difference will increase in training error caused by pruning this subtree.\n",
    "- So $\\alpha_t$ measures error increase per unit of complexity reduction.\n",
    "\n",
    "$$\n",
    "\\alpha_t = \\frac{\\text{increase in training error}}{\\text{number of leaves removed}}\n",
    "$$\n",
    "\n",
    "CART wants to prune, subtrees that don’t reduce error much but add a lot of complexity. So it removes the subtree with smallest $\\alpha_t$\n",
    "\n",
    "CART does not choose alpha upfront. Alpha emerges from the tree structure itself. \n",
    "\n",
    "- The tree has a finite number of internal nodes\n",
    "- CART computes a finite set of critical alpha values.\n",
    "- The smallest alpha corresponds to the weakest link\n",
    "- That subtree is pruned first\n",
    "- CART may prune multiple internal nodes at the same step if they have the same weakest alpha.\n",
    "- The pruning step will be over till it reaches the single node tree.\n",
    "- Each pruning step produces one alpha breakpoint\n",
    "\n",
    "In scikit-learn; \n",
    "\n",
    "`path = tree.cost_complexity_pruning_path(X, y)`\n",
    "\n",
    "This returns sorted alpha breakpoints and the impurities corresponding subtree errors. Each `ccp-alpha[i]` prunes the tree up to that step.\n",
    "\n",
    "CART computes a critical α value for each internal node. At each pruning step, it collapses all internal nodes with the smallest α, then recomputes these values. This process continues until the tree reduces to a single leaf, producing a finite, nested sequence of trees indexed by increasing α\n",
    "\n",
    "We can select $T^*$ with the minimum validation error. Only T* goes to production. \n",
    "\n",
    "**Alpha - average increase in error per leaf that would be removed** if we prune that subtree.\n",
    "\n",
    "So if the alpha is high then we cannot prune that part of the tree ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05a4302-4146-4c9a-8400-dc66e56ca86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.sort(np.random.rand(200, 1), axis=0)\n",
    "y = np.sin(6 * X).ravel() + np.random.normal(0, 0.2, size=200)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503792a1-790f-475a-8490-01e3f3c44ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R²: 1.0\n",
      "Val R²: 0.8723387998051151\n"
     ]
    }
   ],
   "source": [
    "tree_full = DecisionTreeRegressor(random_state=42)\n",
    "tree_full.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train R²:\", tree_full.score(X_train, y_train))\n",
    "print(\"Val R²:\", tree_full.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eec904f8-c224-4086-a2d8-10b3a4daea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = tree_full.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "ccp_alphas = path.ccp_alphas\n",
    "impurities = path.impurities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d9d417-9186-4494-bc2d-349e900f2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = []\n",
    "for alpha in ccp_alphas:\n",
    "    tree = DecisionTreeRegressor(random_state=42, ccp_alpha=alpha)\n",
    "    tree.fit(X_train, y_train)\n",
    "    trees.append(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb360563-2c43-4584-a135-97b726b682f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHUCAYAAAAp/qBkAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbeJJREFUeJzt3XdclXUbx/HPYW/cIII4cC8Uc2BuAfdObDh6bNhytMzM1JZlmWamVqY21MxMyzJzm7PUsEzNzG2Ke+ACzjn38wd5ktAjKHA48H2/Xuf1yH3uccHdU19vfue6TIZhGIiIiIiIOCEXRxcgIiIiInKrFGZFRERExGkpzIqIiIiI01KYFRERERGnpTArIiIiIk5LYVZEREREnJbCrIiIiIg4LYVZEREREXFaCrMiIiIi4rQUZkXklvz222/cf//9lC1bFi8vL/z8/KhTpw5jxozh9OnTOXLN1157jQULFmT5uGPHjvHcc89Ro0YN/Pz88PLyokKFCgwcOJDdu3dnf6HZaOTIkZhMphy9RpkyZejbt6/t6yNHjjBy5Ei2bt2ardeZMWMGJpPJ9nJzcyM0NJT777+fv//+O1uvlRV9+/alTJkyDru+iNweN0cXICLO58MPP+TRRx+lUqVKPPPMM1StWpXU1FQ2b97MlClT2LBhA/Pnz8/267722mt0796dzp07Z/qYn3/+mfbt22MYBo8//jgNGzbEw8ODXbt28dlnn1GvXj3OnDmT7bU6k/nz5xMQEGD7+siRI4waNYoyZcoQGRmZ7debPn06lStX5vLly/z444+MHj2a1atXs23bNnx9fbP9ejczfPhwBg4cmOvXFZHsoTArIlmyYcMGHnnkEWJiYliwYAGenp6292JiYnjqqadYvHixAyv81/nz5+nUqRNeXl6sX7+e0NBQ23vNmjXj4Ycf5ssvv3RghXlD7dq1c/V61atXp27dugA0b94ci8XCyy+/zIIFC7j33nuve8ylS5fw8fHJkXrKly+fI+cVkdyhZQYikiWvvfYaJpOJDz74IF2QvcrDw4OOHTvavrZarYwZM4bKlSvj6elJiRIl6N27N4cPH053XEJCAu3bt6dEiRJ4enoSEhJCu3btbPuZTCYuXrzIxx9/bPs1dbNmzezW+uGHH5KYmMiYMWPSBdlrde/ePd3X33zzDQ0bNsTHxwd/f39iYmLYsGFDun2u/ur/t99+46677iIwMJAiRYrw5JNPYjab2bVrF61bt8bf358yZcowZsyYdMevWrUKk8nEZ599xpNPPklwcDDe3t40bdqUhIQEu9/TVXPmzKFhw4b4+vri5+dHXFxcumPXrl2Lu7s7Tz/9dLrjrv6q/6OPPrJtu3aZwapVq7jjjjsAuP/++20/65EjR/Lpp59iMpky/DwAXnrpJdzd3Tly5Eim6r9WgwYNADhw4ACQ9mt/Pz8/tm3bRmxsLP7+/rRs2TJDrddq1qxZun8erv6MZ8+ezbBhwwgJCSEgIIBWrVqxa9eudMdeb5mByWTi8ccf59NPP6VKlSr4+PhQq1Ytvv322wzX/vrrr6lZsyaenp6UK1eOd955J1eWh4hIGoVZEck0i8XCihUriIqKIiwsLFPHPPLIIwwZMoSYmBi++eYbXn75ZRYvXkx0dDQnT54E4OLFi8TExHDs2DHee+89li5dyvjx4yldujRJSUlA2hNhb29v2rZty4YNG9iwYQOTJk2ye+0lS5bg6upKhw4dMlXrrFmz6NSpEwEBAcyePZuPPvqIM2fO0KxZM9auXZth/x49elCrVi3mzZvHgw8+yLhx4xg8eDCdO3emXbt2zJ8/nxYtWjBkyBC++uqrDMc///zz7N27l6lTpzJ16lSOHDlCs2bN2Lt3r906X3vtNe6++26qVq3KF198waeffkpSUhKNGzdmx44dANx555288sorjB07lm+++QaA7du389hjj3HffffRr1+/6567Tp06TJ8+HYAXXnjB9rN+4IEHiI+PJzg4mPfeey/dMWazmffff58uXboQEhJy8x/0f/z1118AFC9e3LYtJSWFjh070qJFC77++mtGjRqV5fNC2s/4wIEDTJ06lQ8++IDdu3fToUMHLBbLTY/97rvvmDhxIi+99BLz5s2jSJEidOnSJd39Wbx4MV27dqVo0aLMmTOHMWPGMHv2bD7++ONbqldEboEhIpJJiYmJBmD07NkzU/vv3LnTAIxHH3003faffvrJAIznn3/eMAzD2Lx5swEYCxYssHs+X19fo0+fPpmut3LlykZwcHCm9rVYLEZISIhRo0YNw2Kx2LYnJSUZJUqUMKKjo23bRowYYQDG2LFj050jMjLSAIyvvvrKti01NdUoXry40bVrV9u2lStXGoBRp04dw2q12rbv37/fcHd3Nx544IEM17rq4MGDhpubm/HEE0+ku3ZSUpIRHBxs9OjRw7bNarUabdu2NQoVKmT8/vvvRtWqVY3KlSsbFy5cSHdseHh4up/rpk2bDMCYPn16hp/TiBEjDA8PD+PYsWO2bXPmzDEAY/Xq1Rn2v9b06dMNwNi4caORmppqJCUlGd9++61RvHhxw9/f30hMTDQMwzD69OljAMa0adMynOO/tV7VtGlTo2nTpravr/6M27Ztm26/L774wgCMDRs22Lb16dPHCA8PT7cfYAQFBRnnz5+3bUtMTDRcXFyM0aNH27bdcccdRlhYmJGcnGzblpSUZBQtWtTQf2JFcoeezIpIjlm5ciVAhl8L16tXjypVqrB8+XIAIiIiKFy4MEOGDGHKlCm2p4uZZTab070Mw8hyrbt27eLIkSP06tULF5d//9Xo5+dHt27d2LhxI5cuXUp3TPv27dN9XaVKFUwmE23atLFtc3NzIyIiwvYr9Gvdc8896X4VHR4eTnR0tO3ndj0//PADZrOZ3r17p/uevby8aNq0KatWrbLtazKZ+OSTT/D396du3brs27ePL7744rY+ZPXII48AaUs4rpo4cSI1atSgSZMmmTpHgwYNcHd3x9/fn/bt2xMcHMz3339PUFBQuv26det2y3Vede2SF4CaNWsCXPd+/Ffz5s3x9/e3fR0UFESJEiVsx168eJHNmzfTuXNnPDw8bPv5+fll+rcBInL7FGZFJNOKFSuGj48P+/bty9T+p06dAqBkyZIZ3gsJCbG9HxgYyOrVq4mMjOT555+nWrVqhISEMGLECFJTU296HXd393Svq7/iLV26NCdOnODixYu3XavVas3Q9aBIkSLpvvbw8MDHxwcvL68M269cuZLhvMHBwdfddrWW6zl27BgAd9xxR4bve86cObalG1cVLVqUjh07cuXKFVq3bk2NGjVueO7MCAoKIj4+nvfffx+LxcJvv/3GmjVrePzxxzN9jk8++YRNmzaRkJDAkSNH+O2332jUqFG6fXx8fNJ1WLhVRYsWTff11XXely9fzvKxV4+/euyZM2cwDCNDCAeuu01Ecoa6GYhIprm6utKyZUu+//57Dh8+fMMPVV11NQwcPXo0w75HjhyhWLFitq9r1KjB559/jmEY/Pbbb8yYMYOXXnoJb29vnnvuObvX2bRpU7qvy5YtC0BcXBxLlixh4cKF9OzZM9O1/teRI0dwcXGhcOHCds+RVYmJidfddr0QddXVn9mXX35JeHj4Ta+xdOlSJk+eTL169Zg/fz7z5s277SeeAwcO5NNPP+Xrr79m8eLFFCpU6IZdCK6nSpUqtm4GN3KjD095eXmRnJycYfvJkyfT/fOUGwoXLozJZLL9BeNa17u3IpIz9GRWRLJk6NChGIbBgw8+SEpKSob3U1NTWbhwIQAtWrQA4LPPPku3z6ZNm9i5c6ftE+rXMplM1KpVi3HjxlGoUCF++eUX23vXPhW7Vt26ddO9robBfv36ERwczLPPPnvDpvxXP5hVqVIlSpUqxaxZs9ItU7h48SLz5s2zdTjITrNnz053rQMHDrB+/Xq7XRri4uJwc3Njz549Gb7vq6+rjh49yn333UfTpk1Zv349HTt2pF+/fjd9sn6zp5dRUVFER0fzxhtvMHPmTPr27Ztr/WHLlCnDb7/9lm7bn3/+maFDQW7w9fWlbt26LFiwIN3/Fy5cuHDdrgcikjP0ZFZEsqRhw4ZMnjyZRx99lKioKB555BGqVatGamoqCQkJfPDBB1SvXp0OHTpQqVIlHnroId59911cXFxo06YN+/fvZ/jw4YSFhTF48GAAvv32WyZNmkTnzp0pV64chmHw1VdfcfbsWWJiYmzXrlGjBqtWrWLhwoWULFkSf39/KlWqdMNaAwMD+frrr2nfvj21a9dONzRh9+7dfPbZZ/z666907doVFxcXxowZw7333kv79u15+OGHSU5O5s033+Ts2bO8/vrr2f6zPH78OF26dOHBBx/k3LlzjBgxAi8vL4YOHXrDY8qUKcNLL73EsGHD2Lt3L61bt6Zw4cIcO3aMn3/+GV9fX0aNGoXFYuHuu+/GZDIxa9YsXF1dmTFjBpGRkcTHx7N27dp06zyvVb58eby9vZk5cyZVqlTBz8+PkJCQdJ0KBg4cSHx8PCaTiUcffTTbfzY30qtXL+677z4effRRunXrxoEDBxgzZky6Tgi56aWXXqJdu3bExcUxcOBALBYLb775Jn5+fjk2CU9E/sOBHz4TESe2detWo0+fPkbp0qUNDw8Pw9fX16hdu7bx4osvGsePH7ftZ7FYjDfeeMOoWLGi4e7ubhQrVsy47777jEOHDtn2+eOPP4y7777bKF++vOHt7W0EBgYa9erVM2bMmJHhmo0aNTJ8fHwMIN2n1+1JTEw0hgwZYlSrVs3w8fExPD09jYiICOPhhx82tm3blm7fBQsWGPXr1ze8vLwMX19fo2XLlsa6devS7XO1w8CJEyfSbe/Tp4/h6+ub4fpNmzY1qlWrZvv66iftP/30U2PAgAFG8eLFDU9PT6Nx48bG5s2br3ut/1qwYIHRvHlzIyAgwPD09DTCw8ON7t27G8uWLTMMwzCGDRtmuLi4GMuXL0933Pr16w03Nzdj4MCBtm3X6xAwe/Zso3Llyoa7u7sBGCNGjEj3fnJysuHp6Wm0bt06Q203crWbwaZNm+zud6Ofo2GkdWgYM2aMUa5cOcPLy8uoW7eusWLFiht2M5g7d2664/ft25ehU8ONuhk89thjGa5/vZ/V/PnzjRo1ahgeHh5G6dKljddff90YMGCAUbhwYbvfp4hkD5Nh3MLHfkVE5JatWrWK5s2bM3fu3AxDG5zFwoUL6dixI9999x1t27Z1dDl5SmpqKpGRkZQqVYolS5Y4uhyRfE/LDEREJNN27NjBgQMHeOqpp4iMjEzXhqyg6tevHzExMZQsWZLExESmTJnCzp07eeeddxxdmkiBoDArIiKZ9uijj7Ju3Trq1KljGy1c0CUlJfH0009z4sQJ3N3dqVOnDosWLaJVq1aOLk2kQNAyAxERERFxWmrNJSIiIiJOS2FWRERERJyWwqyIiIiIOK0C9wEwq9XKkSNH8Pf31wcXRERERPIgwzBISkoiJCQEFxf7z14LXJg9cuQIYWFhji5DRERERG7i0KFDhIaG2t2nwIVZf39/IO2HExAQ4OBqREREROS/zp8/T1hYmC232VPgwuzVpQUBAQEKsyIiIiJ5WGaWhOoDYCIiIiLitBRmRURERMRpKcyKiIiIiNMqcGtmRUREJHcYhoHZbMZisTi6FMmD3N3dcXV1ve3zKMyKiIhItktJSeHo0aNcunTJ0aVIHmUymQgNDcXPz++2zqMwKyIiItnKarWyb98+XF1dCQkJwcPDQ4OKJB3DMDhx4gSHDx+mQoUKt/WEVmFWREREslVKSgpWq5WwsDB8fHwcXY7kUcWLF2f//v2kpqbeVpjVB8BEREQkR9xsDKkUbNn1tF7/lImIiIiI01KYFRERERGn5dAw++OPP9KhQwdCQkIwmUwsWLDgpsesXr2aqKgovLy8KFeuHFOmTMn5QkVERERuQbNmzRg0aJCjy8jXHBpmL168SK1atZg4cWKm9t+3bx9t27alcePGJCQk8PzzzzNgwADmzZuXw5WKiIhIfmYymey++vbte0vn/eqrr3j55Zdvq7a+ffva6nBzc6N06dI88sgjnDlzxrbPBx98QKtWrahVqxZxcXGcPn36tq7pTBzazaBNmza0adMm0/tPmTKF0qVLM378eACqVKnC5s2beeutt+jWrVsOVXl7DMPg8JnLhBXRpzlFRETyqqNHj9r+PGfOHF588UV27dpl2+bt7Z1u/9TUVNzd3W963iJFimRLfa1bt2b69OmYzWZ27NjB//73P86ePcvs2bMB6NOnDw899BAArVq14qeffspSxnJmTrVmdsOGDcTGxqbbFhcXx+bNm0lNTb3uMcnJyZw/fz7dKzet3HWcpm+uZEHC37l6XRERkbzEMAwupZhz/WUYRqbqCw4Otr0CAwMxmUy2r69cuUKhQoX44osvaNasGV5eXnz22WecOnWKu+++m9DQUHx8fKhRo4YtXF7132UGZcqU4bXXXuN///sf/v7+lC5dmg8++OCm9Xl6ehIcHExoaCixsbHEx8ezZMmSdO8DTJs2jeLFi9O6detMfd/5gVP1mU1MTCQoKCjdtqCgIMxmMydPnqRkyZIZjhk9ejSjRo3KrRIzmJ9wBKsB3207SufapRxWh4iIiCNdTrVQ9cUfcv26O16Kw8cje+LOkCFDGDt2LNOnT8fT05MrV64QFRXFkCFDCAgI4LvvvqNXr16UK1eO+vXr3/A8Y8eO5eWXX+b555/nyy+/5JFHHqFJkyZUrlw5U3Xs3buXxYsXp3synJKSwjPPPIOPjw+fffZZgRpS4VRPZiFjT7Krf+O60U0bOnQo586ds70OHTqU4zVeK65aWvg+d+n6T45FRETEOQwaNIiuXbtStmxZQkJCKFWqFE8//TSRkZGUK1eOJ554gri4OObOnWv3PG3btuXRRx8lIiKCIUOGUKxYMVatWmX3mG+//RY/Pz+8vb0pX748O3bsYMiQIbb3n3nmGT7++GNWrlxJo0aN+PLLL7PjW3YKTvVkNjg4mMTExHTbjh8/jpubG0WLFr3uMZ6enrZH747g45E20eJyqsVhNYiIiDiat7srO16Kc8h1s0vdunXTfW2xWHj99deZM2cOf//9N8nJySQnJ+Pr62v3PDVr1rT9+epyhuPHj9s9pnnz5kyePJlLly4xdepU/vzzT5544gnb+++88w7vvPPOLXxXzs+pwmzDhg1ZuHBhum1Lliyhbt26mVqE7QiB3ml1nbmU4uBKREREHMdkMmXbr/sd5b8hdezYsYwbN47x48dTo0YNfH19GTRoECkp9v+b/9/MYjKZsFqtN712REQEABMmTKB58+aMGjXqtjsl5AcOXWZw4cIFtm7dytatW4G01ltbt27l4MGDQNoSgd69e9v279+/PwcOHODJJ59k586dTJs2jY8++oinn37aEeVnytUwm3TF7OBKREREJDutWbOGTp06cd9991GrVi3KlSvH7t27c+XaI0aM4K233uLIkSO5cr28zKFhdvPmzdSuXZvatWsD8OSTT1K7dm1efPFFIK1NxtVgC1C2bFkWLVrEqlWriIyM5OWXX2bChAl5ti0XgPc/fwu9lKIwKyIikp9ERESwdOlS1q9fz86dO3n44YczLIfMKc2aNaNatWq89tpruXK9vMyhz/ubNWtmt2XGjBkzMmxr2rQpv/zySw5Wlb08XNP+vpBqMbBaDVxcCs6nC0VERPKz4cOHs2/fPuLi4vDx8eGhhx6ic+fOnDt3Lleu/+STT3L//fczZMgQwsLCcuWaeZHJyGwDtnzi/PnzBAYGcu7cOQICAnL8emaLlSovLibVYrDuuRaUKuR984NERESc2JUrV9i3bx9ly5bFy8vL0eVIHmXvn5Os5DWna83lbNxcXQj09gDgzEV9CExEREQkOynM5oJShdL+tnHw9CUHVyIiIiKSvyjM5oLyxf0A2HfyooMrEREREclfFGZzQZliaX3pDpxSmBURERHJTgqzuaCwT1qv2fOX1Z5LREREJDspzOaCEgFpa2Y3HzjD5RSNtRURERHJLgqzuaBF5RKEFfHm5IVkZv50wNHliIiIiOQbCrO5wN3Vhceapc1T/nLLYQdXIyIiIpJ/KMzmkmaVSgCw+/gFTl1IdnA1IiIiIvmDwmwuCQ70okapQCxWgwVbjzi6HBEREckBzZo1Y9CgQbavy5Qpw/jx4+0eYzKZWLBgwW1fO7vO42wUZnNR2xolAdh66KxjCxEREZF0OnToQKtWra773oYNGzCZTPzyyy9ZPu+mTZt46KGHbre8dEaOHElkZGSG7UePHqVNmzbZeq3/mjFjBiaTyfYKCgqiQ4cObN++3bbPTz/9RExMDA0aNKB27dps3rw5R2tSmM1FZYv5AHD4jCaBiYiI5CX9+vVjxYoVHDiQ8YPa06ZNIzIykjp16mT5vMWLF8fHxyc7Sryp4OBgPD09c/w6AQEBHD16lCNHjvDdd99x8eJF2rVrR0pKCgCRkZEsXbqUjRs30q1bN+bOnZuj9SjM5qLQwlfD7GUHVyIiIpLLDANSLub+yzAyVV779u0pUaIEM2bMSLf90qVLzJkzh379+nHq1CnuvvtuQkND8fHxoUaNGsyePdvuef+7zGD37t00adIELy8vqlatytKlSzMcM2TIECpWrIiPjw/lypVj+PDhpKamAmlPRkeNGsWvv/5qezp6teb/LjPYtm0bLVq0wNvbm6JFi/LQQw9x4cIF2/t9+/alc+fOvPXWW5QsWZKiRYvy2GOP2a51IyaTieDgYEqWLEndunUZPHgwBw4cYNeuXQC2QL1582aWLFnC008/bfd8t8stR88u6YQV8cHFBCeSklm167jtQ2EiIiL5XuoleC0k96/7/BHw8L3pbm5ubvTu3ZsZM2bw4osvYjKZAJg7dy4pKSnce++9XLp0iaioKIYMGUJAQADfffcdvXr1oly5ctSvX/+m17BarXTt2pVixYqxceNGzp8/n2597VX+/v7MmDGDkJAQtm3bxoMPPoi/vz/PPvss8fHx/P777yxevJhly5YBEBgYmOEcly5donXr1jRo0IBNmzZx/PhxHnjgAR5//PF0gX3lypWULFmSlStX8tdffxEfH09kZCQPPvjgTb8fgLNnzzJr1iwA3N3dbds/+ugjFi1axIIFCyhSpEimznWr9GQ2FwV6u9OrQTgAT8/9lRNJ6mogIiKSV/zvf/9j//79rFq1yrZt2rRpdO3alcKFC1OqVCmefvppIiMjKVeuHE888QRxcXGZ/jX6smXL2LlzJ59++imRkZE0adKE1157LcN+L7zwAtHR0ZQpU4YOHTrw1FNP8cUXXwDg7e2Nn58fbm5uBAcHExwcjLe3d4ZzzJw5k8uXL/PJJ59QvXp1WrRowcSJE/n00085duyYbb/ChQszceJEKleuTPv27WnXrh3Lly+3+32cO3cOPz8/fH19KVy4MJ9//jkdO3akcuXKAMyfP5+HH36Yw4cP07ZtW55//vlM/XxulZ7M5rKhbauwce9pdh1L4rl5v/FR3zscXZKIiEjOc/dJe0rqiOtmUuXKlYmOjmbatGk0b96cPXv2sGbNGpYsWQKAxWLh9ddfZ86cOfz9998kJyeTnJyMr+/Nn/wC7Ny5k9KlSxMaGmrb1rBhwwz7ffnll4wfP56//vqLCxcuYDabCQgIyPT3cfVatWrVSldbo0aNsFqt7Nq1i6CgIACqVauGq6urbZ+SJUuybds2u+f29/fnl19+wWw2s3r1at58802mTJlie79Lly6YzeYs1Xs79GQ2l3m5uzLh7tp4uLqw/I/jrNp13NEliYiI5DyTKe3X/bn9+me5QGb169ePefPmcf78eaZPn054eDgtW7YEYOzYsYwbN45nn32WFStWsHXrVuLi4mwffLoZ4zrrd03/qW/jxo307NmTNm3a8O2335KQkMCwYcMyfY1rr/Xfc1/vmtcuDbj6ntVqtXtuFxcXIiIiqFy5Mg8//DC9evUiPj4+S/VlJ4VZB6gU7E+f6LTlBq9+txOzxf4/NCIiIpI7evTogaurK7NmzeLjjz/m/vvvt4W/NWvW0KlTJ+677z5q1apFuXLl2L17d6bPXbVqVQ4ePMiRI/8+od6wYUO6fdatW0d4eDjDhg2jbt26VKhQIUOHBQ8PDywWy02vtXXrVi5evJju3C4uLlSsWDHTNWfG4MGD+fXXX5k/f362njezFGYd5PHmFSjk487u4xeYs/mQo8sRERERwM/Pj/j4eJ5//nmOHDlC3759be9FRESwdOlS1q9fz86dO3n44YdJTEzM9LlbtWpFpUqV6N27N7/++itr1qxh2LBh6faJiIjg4MGDfP755+zZs4cJEyZkCIllypRh3759bN26lZMnT5KcnPEzOPfeey9eXl706dOH33//nZUrV/LEE0/Qq1cv2xKD7BIQEMADDzzAiBEjrvv0OacpzDpIoI87g1pWAGDskj85fv6KgysSERERSFtqcObMGVq1akXp0qVt24cPH06dOnWIi4ujWbNmBAcH07lz50yf18XFhfnz55OcnEy9evV44IEHePXVV9Pt06lTJwYPHszjjz9OZGQk69evZ/jw4en26datG61bt6Z58+YUL178uu3BfHx8+OGHHzh9+jR33HEH3bt3p2XLlkycODFrP4xMGjhwIDt37szxnrLXYzIcEaEd6Pz58wQGBnLu3LksL6bObqkWKx0nrmPn0fNEly/Kp/3q4+qStbU9IiIiec2VK1fYt28fZcuWxcvLy9HlSB5l75+TrOQ1PZl1IHdXF969uzbe7q6s33OKKav3OLokEREREaeiMOtgESX8eKlTNQDeXvonm/efdnBFIiIiIs5DYTYP6B4VSqfIECxWg4Gfb+Xspay13xAREREpqBRm8wCTycQrnasTXtSHv89eZsi837BaC9RSZhEREZFbojCbW1KvwPfPwc5vr/u2v5c7795dG3dXEz9sP0af6T9z8oLG3YqIiPMqYJ8xlyzKrn8+FGZzy/b58NNkmHMvJB277i41QwsxtkckXu4urNl9krbvrGHj3lO5XKiIiMjtuTpV6tKlSw6uRPKyq1PNrh2neyvcsqMYuYklw2H9hH+/3vYFRD9x3V071gqhcrA/j878hb+OX+CeDzcyqFVFHmseobZdIiLiFFxdXSlUqBDHj6eNbPfx8bnhaFUpmKxWKydOnMDHxwc3t9uLo+ozmxtGBqb/unJ76DnT7iGXUswMX7Cdeb8cBuDOiGKMi4+kuL9nTlUpIiKSbQzDIDExkbNnzzq6FMmjXFxcKFu2LB4eHhney0peU5jNDf8Ns0XKwYCETB365ZbDDF/wO5dTLRT39+Sd+EiiI4rlQJEiIiLZz2KxkJqa6ugyJA/y8PDAxeX6K16zkte0zCCnXbpO39jT+9JeRcre9PDuUaHUCg3ksVm/8OexC9z70U8MaFGBAS0raNmBiIjkea6urre9JlLEHn0ALKdZzf/+ucVwKN8CMGDd+EyfokKQP18/dic96oZiGPDO8t3cN/UnjiddyfZyRURERJyJwmxOs1r+/XOTp6HJM2l/3joLzh/J9Gm8PVwZ070W4+Jr4ePhyoa9p2j7zhrW7j6ZzQWLiIiIOA+F2Zx25Jf0X4dHQ+losKTA6jGQxSXLXWqH8s3jd1I52J+TF1LoNe0n3l6yC4uGLIiIiEgBpDCb007vy7itydNp/7tlOsxoB8d3ZumUESX8WPBYI+6uF4ZhwIQVf3HPhxs5dl7LDkRERKRgUZjNaUuGZdxWvgXEvgJu3nBgHUxvC5fPZum0Xu6ujO5ak3d6RuLr4cpP+07T9p01rP7zRPbULSIiIuIEFGYdwWRKG5rw+CYoVhEun4aNk27pVJ0iS7HwiTupUjKAUxdT6DPtZ9784Q/MFms2Fy0iIiKS9yjMOlKhMGjxQtqfN0y6fhuvTChX3I/5j0Zzb/3SALy3cg/3fPgTR89dzq5KRURERPIkhdmcNiwR7ngABv1+/fcrd4CgGpCSBBsm3vJlvNxdebVLDd69uzZ+nm78vD9t2cHKXcdv+ZwiIiIieZ3CbE5z94Z2Y9Oewl6Piws0H5r2541T4OLttdrqUCuEhU/cSbWQAM5cSuX+6Zt4/fs/SNWyAxEREcmHFGbzgkptoWQkpF6Ede/c9unKFvNl3iPR9GoQDsCU1Xvo+cFGjpzVsgMRERHJXxRm8wKTCZr/0/Xg5w/hwu0vDfByd+XlztV57546+Hu6seXAGdpOWMPyncdu+9wiIiIieYXCbF5RIQZK1QXzZVg7PttO265mSb4dcCfVSwVw9lIq/T7ezLIdCrQiIiKSPyjM5hUmEzR/Pu3Pmz+C3+dleTrYjYQXTVt2EFM1CIAV+lCYiIiI5BMKs3lJ+RZpL/MV+PJ/8Fk3OL03W07t6eZKZFghAPWgFRERkXxDYTYvMZmg52xo9jy4esKe5TCpIax+E8zJt316D9e0251qyZ4nviIiIiKOpjCb17h7QbMh8OgGKNcs7Sntyldgyp2wb83tndrVBKA2XSIiIpJvKMzmVUXLQ68F0O0j8C0BJ/+Ej9vD/P5w4cQtndLN9mRWYVZERETyB4XZvMxkghrd4fFNaVPEMMGvs2FiXdgyA6xZC6VXlxmYtcxARERE8gmFWWfgXShtitgDyyC4Blw5CwsHwvTWcGx7pk/j9s8ygxQ9mRUREZF8QmHWmYTWhQdXQdxo8PCDQz/BlMawZDikXLzp4e56MisiIiL5jMKss3F1g4aPwmM/Q5UOYFhg/QR4rz7s+t7uoe5aMysiIiL5jMKsswosBfGfwd1zILA0nDsEs3vC5/fC2UPXPUTdDERERCS/UZh1dpVaw2M/wZ2DwcUN/vg27Snt+nfBkppuV3f1mRUREZF8RmE2P/DwgVYjof9aKN0QUi/Ckhfgg2ZwaJNtNy0zEBERkfxGYTY/KVEF+i6CjhPBuzAc+x0+ioGFg+DyGdsyA7NVT2ZFREQkf1CYzW9cXKBOL3h8C0TeCxiwZTpMvIPi+xYABilmPZkVERGR/EFhNr/yLQqdJ0Hf76BYJbh4gvDVg5nl/ip+ljOOrk5EREQkWzg8zE6aNImyZcvi5eVFVFQUa9assbv/zJkzqVWrFj4+PpQsWZL777+fU6dO5VK1TqjMnWlraVu+iNXVk2jXHdxrXuDoqkRERESyhUPD7Jw5cxg0aBDDhg0jISGBxo0b06ZNGw4ePHjd/deuXUvv3r3p168f27dvZ+7cuWzatIkHHngglyt3Mm4e0PgpzkS/AEAp61EHFyQiIiKSPRwaZt9++2369evHAw88QJUqVRg/fjxhYWFMnjz5uvtv3LiRMmXKMGDAAMqWLcudd97Jww8/zObNm3O5cudkKlQKgMLGGR6f9Qv7Tt58apiIiIhIXuawMJuSksKWLVuIjY1Ntz02Npb169df95jo6GgOHz7MokWLMAyDY8eO8eWXX9KuXbsbXic5OZnz58+nexVUhUuEARBsOs13v/1NzNurGTZ/G8fOX3FwZSIiIiK3xmFh9uTJk1gsFoKCgtJtDwoKIjEx8brHREdHM3PmTOLj4/Hw8CA4OJhChQrx7rvv3vA6o0ePJjAw0PYKCwvL1u/DmZgCQwEIMZ3mR//hNGELM386QNM3V/LG4j84dzn1JmcQERERyVsc/gEwk8mU7mvDMDJsu2rHjh0MGDCAF198kS1btrB48WL27dtH//79b3j+oUOHcu7cOdvr0KHrj3otEAJCoPXr4BlIWOo+pnm8xff+r1LDvIPJq/bQZMxKpqzew5VUi6MrFREREckUk2EYDumgn5KSgo+PD3PnzqVLly627QMHDmTr1q2sXr06wzG9evXiypUrzJ0717Zt7dq1NG7cmCNHjlCyZMmbXvf8+fMEBgZy7tw5AgICsuebcTaXTsO6d+Cn98F8GYCf3aIYebEbO4wyBAV4MqhVRe6KCsXN1eF/3xEREZECJit5zWFJxcPDg6ioKJYuXZpu+9KlS4mOjr7uMZcuXcLFJX3Jrq6uQNoTXckknyIQMwoGJEDd/4GLG/XMW1jk+Twf+kzCK+kAQ7/aRuy4H1m07ah+tiIiIpJnOfSx25NPPsnUqVOZNm0aO3fuZPDgwRw8eNC2bGDo0KH07t3btn+HDh346quvmDx5Mnv37mXdunUMGDCAevXqERIS4qhvw3kFlIT24+Cxn6F6dwBirGtZ6fUsb3lP58LJwzw68xc6vbeOtbtPOrhYERERkYwctszgqkmTJjFmzBiOHj1K9erVGTduHE2aNAGgb9++7N+/n1WrVtn2f/fdd5kyZQr79u2jUKFCtGjRgjfeeINSpUpl6npaZmDH0d9gxcuwewkAqS6efGKJY0Jye87hx50RxXi2dSVqhhZybJ0iIiKSr2Ulrzk8zOY2hdlMOLAelo2CQxsBuOLqx3sp7ZiaGsdlvGhbI5inYitRvrifgwsVERGR/Ehh1g6F2UwyjLQntMtfgmO/A3DetQhvXenIbEsLrC7u9KgbysCWFQkO9HJwsSIiIpKfKMzaoTCbRVYr/D4PVr4CZ/YDcMItmFcvdeUbazTubm70bVSGR5qWp5CPh2NrFRERkXxBYdYOhdlbZE6BhE9g9Ri4cAyAg25lGHWpG8utdfD3cqd/0/Lc36gMPh5uDi5WREREnJnCrB0Ks7cp5WJaf9p14+HKOQC2u1Zh1KXu/GxUobi/JwNbViD+jjDc1aNWREREboHCrB0Ks9nk8pm0wQsbp9gGL2x0qc3Ll+9iu1GGMkV9eCq2Eu1qlMTF5foT3URERESuR2HWDoXZbJaUmLb04JePwWoG4AdTNKOvdGO/UZJqIQE827oyTSoUu+GYYhEREZFrKczaoTCbQ07vhZWvwbYvAQMrrnxpNGdscmeOUYQG5YowpHVlapcu7OhKRUREJI9TmLVDYTaHJW6D5S/D7h8ASDV5MMMcx8TUDpzDj7hqQTwTV4mIEv4OLlRERETyKoVZOxRmc8mBDbB8FBzcAMBlFz/eS2nLNHNrrpi86B4VyqBWFQkp5O3gQkVERCSvUZi1Q2E2FxkG7F6aFmptgxcK8daVTsy2tMTk5kGfhuE82iyCwr7qUSsiIiJpFGbtUJh1AKsVtn8FK16BM/sAOO4axOjLXfna2ghfTw8ealKO/91ZFl9P9agVEREp6BRm7VCYdSBLKvxydfBCIgD7XUrzypW7WGatQzE/Lwa0jKDnHaXxcFOPWhERkYJKYdYOhdk8IOUS/Pw+rB1nG7zwu0slXr7cg5+MKoQV8eapmEp0rBWiHrUiIiIFkMKsHQqzecjlM7BuAmycbBu8sN4UyatX7mK7UZbKwf4MaV2ZZpWKq0etiIhIAaIwa4fCbB6UlAg/vglbZtgGLyw2GvJGSnf2GSWpV7YIQ1pXIiq8iGPrFBERkVyhMGuHwmwednovrBwN2+ZydfDCXGtTxqV0IZGitKqS1qO2UrB61IqIiORnCrN2KMw6gcTfYcXL8OdiIG3wwvTUGCaZO3LO5E/X2qEMjqlAaGEfBxcqIiIiOUFh1g6FWSdycCMsGwUH1wNw2cWX95LbMs3SBrOrD/c1COex5uUp6ufp4EJFREQkOynM2qEw62QMA/5aljZ4IXEbAOdcCvF2cidmW1rg7uHFg03K8UDjcvipR62IiEi+oDBrh8Ksk7rO4IVjLiV440pXFljvpLCvF4+3iOCe+qXxdHN1cLEiIiJyOxRm7VCYdXKWVEj4NG3wQtJRAPa5lOa1K91Zao0itLAPT8ZUpFNkKVzVo1ZERMQpKczaoTCbT6Rcgp8/+GfwwlkAtpkq8mpyDzZaq1IpyJ9n4irRskoJ9agVERFxMgqzdijM5jOXz8L6fwYvpF4CYB21GJ18F78b5agbXpghbSpzRxn1qBUREXEWCrN2KMzmU0nHrhm8kArA99YGvJnanb1GCC0ql+CZuEpUKal7LiIiktcpzNqhMJvPnd4Hq0bDb18ABhZc+dLShHGpXTlmKkrnyFI8GVORsCLqUSsiIpJXKczaoTBbQBzbDstfhj+/ByDV5M701FgmmTty0TWAe+uH81jzCIr7q0etiIhIXqMwa4fCbAFz8Ke0HrUH1gFwyeTD5JS2fGRpCx6+PHBnWR5sUg5/L3cHFyoiIiJXKczaoTBbABkG/LUclo+0DV44awpkfEonZlla4uvjw2PNI7ivQThe7upRKyIi4mgKs3YozBZgVivsmA8rXoXTewBINJXgzeSuzLfeSclCvgxqVYGudULVo1ZERMSBFGbtUJiVtMELn8HqN2yDF/aawng9uTtLrHWpUMKfp+MqEVs1SD1qRUREHEBh1g6FWbFJvZw2eGHN27bBC79RgdEpPdhgrUbt0oUY0royDcoVdWydIiIiBYzCrB0Ks5LB5bOw/l3YOOnfwQtGTV5P6cE2oxxNKxbn2daVqBYS6Ng6RURECgiFWTsUZuWGko7Bmrdg8/RrBi/U583Uu9hrhNCxVghPxlSkTDFfBxcqIiKSvynM2qEwKzd1Zj+sHA2/zSFt8IILc81NeMfcjRMuxehZL4wBLStQwt/L0ZWKiIjkSwqzdijMSqYd2wErXoFd3wGQgjsfm2OYZO7IFffC/O/OMjzctDwB6lErIiKSrRRm7VCYlSw79DMsGwUH1gJwyeTNlJR2fGRpg7tPAI82K0/vhmXUo1ZERCSbKMzaoTArt8QwYM/ytFCb+BsAZ0yBTEjpyExLK4oG+jOoVQW61QnFzdXFwcWKiIg4N4VZOxRm5bZYrbBjQdryg6uDFyjGW6nd+MrSmDLF/XkmthKtqwerR62IiMgtUpi1Q2FWsoUlFbbOhFVvQNIRAPZSijdSevCDtS61QtN61EZHFHNwoSIiIs5HYdYOhVnJVqmX4ecPYe3bcPkMAL8ZEYxOjWeDtRqNKxTj2bjK1AhVj1oREZHMUpi1Q2FWcsSVc2mDFzZMgtSLAKyzVueN1Hh+M8rTrmZJnoqpSLnifg4uVEREJO9TmLVDYVZy1IXj8ONbsHnav4MXLPV4y3wX+02hxN8RxsCWFQgKUI9aERGRG1GYtUNhVnLFmQOwajT8+jlgYLUNXujKafcS9I0uyyNNyxPoox61IiIi/6Uwa4fCrOSq4zvTOh/88S2QNnjhE3MrJpk7YfYqwiPNIugbXQZvD/WoFRERuUph1g6FWXGIQ5tg+SjYvwaAS3jzfmpbplra4hdQiIEtK3JX3VDc1aNWREREYdYehVlxGMOAPSvSQu3RXwE4QwDvpnZipqUlIcUK81RsRdpWL4mLi3rUiohIwaUwa4fCrDic1Qo7v05bfnDqLyBt8MLY1K58ZWlM1VJFeLZ1JRpXKO7gQkVERBxDYdYOhVnJMyzmtMELq9+A838DsMcIYUxqD36w3kGjiLQetbXCCjm2ThERkVymMGuHwqzkOamXYdNUWDP238EL1vK8bo5nvbU6baoH81RsJSJKqEetiIgUDAqzdijMSp515Rysnwgb3rMNXlhrrcaY1J78Tnl61A1jYKsKlAz0dnChIiIiOUth1g6FWcnzLpyANf8MXrCkAPC95Q7eMvfgsGsYfaPL8Eiz8hTy8XBwoSIiIjlDYdYOhVlxGmcOwKrX4bfPwbBixYUvzY0Zb+5Gklcw/ZuW5/5GZfDxcHN0pSIiItlKYdYOhVlxOsf/gBUvXzN4wY1PzTG8Z+6Eq39xBrSsQM87wtSjVkRE8g2FWTsUZsVpHd4My0ZeM3jBiw/MbZlqbkvRosV4MqYiHWqGqEetiIg4PYVZOxRmxakZBuxdCctGwdGtAJzFn3dTO/GZpRXlSxbj2daVaFqxOCaTQq2IiDgnhVk7FGYlXzAM2HF18MJuAI4aRXnb3I2vLI2pW7Y4Q9pUpk7pwg4uVEREJOsUZu1QmJV8xWKGX2elfVDsmsELb6b2YLH1DmKrBvNMXCUqBPk7uFAREZHMU5i1Q2FW8qXUK9cMXjgNwG/WcrxhjmeDUYNudUIZFFORUoXUo1ZERPI+hVk7FGYlX7tyHjb8M3gh5QIA6yzVGGOOZ6dLRXo1DOex5hEU8VWPWhERybuyktcc3stn0qRJlC1bFi8vL6KiolizZo3d/ZOTkxk2bBjh4eF4enpSvnx5pk2blkvViuRxXgHQ/HkYsBXqPwKuHjRy3c7Xni8ywWUsq9etocmYlUxYvpuLyWZHVysiInLbHPpkds6cOfTq1YtJkybRqFEj3n//faZOncqOHTsoXbr0dY/p1KkTx44d45VXXiEiIoLjx49jNpuJjo7O1DX1ZFYKlLMHYdUbGL/OwmRYseDCV+Y7GW/uRrJfKZ5oUYG765XGw83hf68VERGxcZplBvXr16dOnTpMnjzZtq1KlSp07tyZ0aNHZ9h/8eLF9OzZk71791KkSJFbuqbCrBRI1xm88Jm5Fe+ZO+FTJJgnYyrSqVYp9agVEZE8wSmWGaSkpLBlyxZiY2PTbY+NjWX9+vXXPeabb76hbt26jBkzhlKlSlGxYkWefvppLl++fMPrJCcnc/78+XQvkQKnRGXoORMeWA5lm+CBmf+5LeZHr8F0P/8pw+dsoO2ENaz44xgFbBm9iIg4OYeF2ZMnT2KxWAgKCkq3PSgoiMTExOses3fvXtauXcvvv//O/PnzGT9+PF9++SWPPfbYDa8zevRoAgMDba+wsLBs/T5EnEpoXeizEHotgJDa+HKFgW5fscZrMI1OfM4jM9YT//5GNu8/7ehKRUREMsXhC+X+O6XIMIwbTi6yWq2YTCZmzpxJvXr1aNu2LW+//TYzZsy44dPZoUOHcu7cOdvr0KFD2f49iDid8s3hwZXQ4xMoVpHCJDHcfSarPJ+kzKF5xE9ZywMfb+KPRP0mQ0RE8jaHhdlixYrh6uqa4Sns8ePHMzytvapkyZKUKlWKwMBA27YqVapgGAaHDx++7jGenp4EBASke4kIYDJB1U7wyAboOBECQilpOs0Y9w9Z4jkE910LafPOjzz5xVYOnb7k6GpFRESuy2Fh1sPDg6ioKJYuXZpu+9KlS2/YmaBRo0YcOXKECxcu2Lb9+eefuLi4EBoamqP1iuRbrm5Qpxc8sQXiXgOfopQ3HWGyxzt87f4CJ7Z+T4uxKxn5zXZOXkh2dLUiIiLp5InWXFOmTKFhw4Z88MEHfPjhh2zfvp3w8HCGDh3K33//zSeffALAhQsXqFKlCg0aNGDUqFGcPHmSBx54gKZNm/Lhhx9m6prqZiByE1fOpw1d2DDRNnhhvaUqY8w92e1eiQcal+OBxmXx93J3cKEiIpJfZSWvueVSTdcVHx/PqVOneOmllzh69CjVq1dn0aJFhIeHA3D06FEOHjxo29/Pz4+lS5fyxBNPULduXYoWLUqPHj145ZVXHPUtiOQ/XgHQfCjUezBtPO6mqUSzgwWuL/KDpS5vrejBpxsP8HjzCO5tUBpPN1dHVywiIgWYxtmKiH1nD8Hq1zG2/jt4Yb4lbfCCEViawTEV6VK7FK7qUSsiItnEaYYmOILCrMgtOrELVrwCO78BIBU3PjO3ZKK5M0WDSvFMXGVaVSlxw24kIiIimaUwa4fCrMhtOrwFlo+CfasBuIQnH5rbMtXcjorhpRjSujL1yt7ahD4RERFQmLVLYVYkm+xdBctGwZFfADhr+DHR3IlPLTFEVyrFs60rU6Wk/j8mIiJZpzBrh8KsSDYyDNi5MG35wcldABw1ijDe3I151ia0rxXGkzGVKF3Ux8GFioiIM1GYtUNhViQHWMzw2+ew6nU4lzZlb4+1JGPNd7HMVJ+e9crwRIsKFPf3dHChIiLiDBRm7VCYFclB5mTYPA1+fBMunQJgm7UMb5rj2exWm353luPBJuUIUI9aERGxQ2HWDoVZkVyQnJQ2eGH9REhJAmCDpSpjzPHs967KY80juK9BOF7u6lErIiIZKczaoTArkosunoQ1b2NsmorJkjYKd4klijfN8VwMiGBQTEW61i6Fm6vDJmuLiEgepDBrh8KsiAOcOwyrXsfYOhOTYcWKifmWOxln7o5X8bI8HVuJuGpB6lErIiKAwqxdCrMiDnTiT1j5Cuz4GoBUXPnM3Ir3zJ0JDQtnSOvKNCxf1MFFioiIoynM2qEwK5IH/L0Flr+U1qsWuGh48pGlDR+a21O7YjjPxlWieqlAx9YoIiIOozBrh8KsSB6yd3XaNLG/twBwxvBjkrkjn1hiia1VhqdiKlKmmK+DixQRkdymMGuHwqxIHmMY8Me3sPzldIMX3jF3Zb7RjO53lGFgywqUCPBycKEiIpJbFGbtUJgVyaOsFvj1c1g12jZ4Ya81mLHmHqxwbcD9jcrzcNPyBHqrR62ISH6nMGuHwqxIHmcbvPAWXDoJwO//DF7Y6hHFo80j6BNdRj1qRUTyMYVZOxRmRZxEchJsmISx/l1M/wxe2GitwpjUeI7412RgqwrcFRWqHrUiIvmQwqwdCrMiTubiKVj7NsbPH9oGLyy1RPGmuQfmopV5Oq4SbaoHq0etiEg+ojBrh8KsiJM6dxhWv4GR8Nk1gxcaMc7cnSKlKjCkdWUaRRRzdJUiIpINFGbtUJgVcXInd8OKV2DHAgBSDVdmWloy0dyFyhHlebZ1JWqGFnJoiSIicnsUZu1QmBXJJ44kpA1e2LMCgEv/DF74wNyeJjXK81RsRcoV93NwkSIicisUZu1QmBXJZ/b9CMtGwd+bAThr+DLJ3JHPjNZ0qluegS0rEByoHrUiIs5EYdYOhVmRfMgw4I/vYMXLcOIPABKNwrxj7so3pubc1yiCR5qWp5CPh4MLFRGRzFCYtUNhViQfs1rgtzmwcjScOwjAPmsQb5vv4kePO3m4WQXujy6Lt4d61IqI5GUKs3YozIoUAOZk2Dwd48c3Mf0zeGG7NZw3zfHs8KnHwJiK9Kgbhrt61IqI5ElZyWtZ+jf52bNn+eGHH2xff/XVV7dWoYhITnLzhAb9MQ3cCs2HYXgGUM3lADM8xvBuygvMW/AVMW+vZuGvR7BaC9Tf50VE8p0sPZlt06YNZrOZEiVK8Nlnn9GoUSPWr1+fk/VlOz2ZFSmALp1OG7zw0wfXDF6ow1vmHriHVOfZuMo0rlBMgxdERPKIHFtmULt2bRISEpg+fTp//fUXK1euVJgVEedx7u9rBi9YsBomFlgbMc7cjdCyVXm2dSVqly7s6CpFRAq8HFtmUKxY2nSd+++/nwsXLvDHH3/cepUiIrktsBR0nIDpsZ+hWhdcTAZdXdey3ONpWh98i4cmLaL/p1v463iSoysVEZFMylKY7dGjB6mpqQC89dZb9O7dO8M+f//9d/ZUJiKSU4pFwF0z4KFVUL4lHiYLfdyWstpzMNV3vUO3cd/z7Je/cuTsZUdXKiIiN5Ft3QwSExN59dVXmTp1Kpcv593/AGiZgYhksG8NLB8FhzcBaYMXJps7MtvUmviGFXm0WQSFfdWjVkQkt+TYMoNz585x7733Urx4cUJCQpgwYQJWq5UXX3yRcuXKsXHjRqZNm3ZbxYuI5LqyjaHfUug5C4pXoZDpIkPdZ7PUdSAX10+lxZilTFyxm0spZkdXKiIi/5GlJ7OPPvooCxcuJD4+nsWLF7Nz507i4uK4cuUKI0aMoGnTpjlZa7bQk1kRsctqgW1zMVa+iunsv4MXxpnvYoN3U55oVZGed5TGw009akVEckqOdTMIDw/no48+olWrVuzdu5eIiAgGDBjA+PHjb7fmXKMwKyKZYk6GLTPSBi9cPAHADms4Y8zx7A1syFNxlehQMwQXF7XzEhHJbjkWZt3d3Tlw4AAhISEA+Pj48PPPP1O9evXbqzgXKcyKSJYkX4CNkzHWv4MpOa3LwU/WyoxJjedS8B0827oSzSoWV49aEZFslGNrZq1WK+7u7ravXV1d8fX1vbUqRUScgacfNH0G08DfIHoAhpsX9V3+YJ7nKJ46OZw3Zswj/oONbDlwxtGViogUSFl6Muvi4kKbNm3w9PQEYOHChbRo0SJDoM3LY271ZFZEbsv5I2mDF3751DZ44WtrNG+bu1O5Sk2eiatExSB/R1cpIuLUcmyZwf3335+p/aZPn57ZU+Y6hVkRyRYn/4KVr8D2+QCkGq7MtrRgoqUzjWvXYHBMBUIL+zi4SBER55RjYTY/UJgVkWx1ZCuseBn+WgbAZcODaZbWTDM60alBVR5rXp6ifp6OrVFExMkozNqhMCsiOWL/Wlg2Cg7/DMA5w4fJ5o586daOXo2r0K9xWfw83RxcpIiIc1CYtUNhVkRyjGHAru8xVryM6fgOAI4ZhZhg7soyz1j6t6zMPfVL4+nm6uBCRUTyNoVZOxRmRSTHWS2w7UuMla/YBi/stwbxtrk7CQEtGBxbmU6RpXBVj1oRketSmLVDYVZEco055ZrBC8eBq4MXepBYvDHPtK5Mi8ol1KNWROQ/FGbtUJgVkVyXfAF+moyx7t/BCz9bKzEmNR5KN2RIm8rcUaaIg4sUEck7FGbtUJgVEYe5dBrWjcf46X1M5isALLfU5i1zD0Iq3cEzrStROVj/XhIRUZi1Q2FWRBzu/BFYPQbjl09sgxe+sTZknPkuoiLrMDimImFF1KNWRAouhVk7FGZFJM84tQdWvgq/zwPSBi98bmnOZKMrsfUjeax5BMX91aNWRAoehVk7FGZFJM85+issfxn+WgqkDV6YbmnNJy6d6NG4Jg82Lou/l7uDixQRyT0Ks3YozIpInrV/HSwfBYd+AtIGL0wxd+Rrzw70a1GNe+uXxstdPWpFJP9TmLVDYVZE8jTDgD9/wFg+yjZ44bhRiAnmLqzxa8PjMVXpWidUPWpFJF9TmLVDYVZEnILVAr/Pw1jxCqazBwA4YC3B2+bu7Cway9OtqxBTNUg9akUkX1KYtUNhVkScijkFfvkYY/UY2+CFndbSjDHHc65UM4a0qUL9ckUdXKSISPZSmLVDYVZEnFLKRfhpCsba8ZiSzwOwyVqRMak98a3YmGfiKlEtJNDBRYqIZA+FWTsUZkXEqV06Devewdg4BZMlbfDCCkskb5l7EFEzmqdiKxJe1NfBRYqI3B6FWTsUZkUkXzh/FH4cg7HlY0yGBYCvLdFMsNxFdL16PNEyghL+Xg4uUkTk1ijM2qEwKyL5yqk9sPI1+P1LIG3wwhxLMz4wdafjnVE81LQcAepRKyJORmHWDoVZEcmXjv4GK16G3UuAtMELMyxxzHLvSu/mkfRqGK4etSLiNBRm7VCYFZF87cB6jGWjMB3aCMB5w4cp5g5879uJ/jE16FYnFDdXFwcXKSJin8KsHQqzIpLvGQbsXoKxbKRt8MIJI5AJ5i78XLg9g1tXJ65asHrUikiepTBrh8KsiBQYViv8/iXWFa/icnY/AAetxXnbfBcHQtrwTOuqREcUc2yNIiLXkZW85vDfNU2aNImyZcvi5eVFVFQUa9asydRx69atw83NjcjIyJwtUETEWbm4QM0euDy+Cdq+hdW3BKVdTjDeYxKvHX+UqdMm02vqRn7/+5yjKxURuWUOfTI7Z84cevXqxaRJk2jUqBHvv/8+U6dOZceOHZQuXfqGx507d446deoQERHBsWPH2Lp1a6avqSezIlJgpVyEn97HunY8LslpAXaztSJjUuMpUaMFT8VWomwx9agVEcdzmmUG9evXp06dOkyePNm2rUqVKnTu3JnRo0ff8LiePXtSoUIFXF1dWbBggcKsiEhWXD4D697BunEyLua0wQsrLbUYa+1JzbqNGdiyAkEB6lErIo7jFMsMUlJS2LJlC7Gxsem2x8bGsn79+hseN336dPbs2cOIESMydZ3k5GTOnz+f7iUiUqB5F4ZWI3EZ+CvU7YdhcqO566986z6UBr88Q+83Z/HG4j84dynV0ZWKiNyUw8LsyZMnsVgsBAUFpdseFBREYmLidY/ZvXs3zz33HDNnzsTNzS1T1xk9ejSBgYG2V1hY2G3XLiKSL/gHQ/u3MT3+M9S4C4COrhv4zuUpQtc+T7cx85iyeg+XUywOLlRE5MYc/gGw/7aGMQzjuu1iLBYL99xzD6NGjaJixYqZPv/QoUM5d+6c7XXo0KHbrllEJF8pWh66TYX+azEqxOFmsnKv23K+NR6HpSPo+OY3zPrpIGaL1dGViohk4LA1sykpKfj4+DB37ly6dOli2z5w4EC2bt3K6tWr0+1/9uxZChcujKvrvxNsrFYrhmHg6urKkiVLaNGixU2vqzWzIiI3cWDDP4MXNgBXBy+0Z1WhbjwWV4u2NdSjVkRyllOsmfXw8CAqKoqlS5em27506VKio6Mz7B8QEMC2bdvYunWr7dW/f38qVarE1q1bqV+/fm6VLiKSv4U3xPS/7+GeuVhLVCPAdIln3b/g4wsP8dOc0XR9dxVrd590dJUiIgBkbuFpDnnyySfp1asXdevWpWHDhnzwwQccPHiQ/v37A2lLBP7++28++eQTXFxcqF69errjS5QogZeXV4btIiJym0wmqBiLS0Qr+H0e1hWvUPzsfl5y/5iDJxfx9vS7mFK2Pc+0rkatsEKOrlZECjCHhtn4+HhOnTrFSy+9xNGjR6levTqLFi0iPDwcgKNHj3Lw4EFHligiUrC5uEDNu3Cp2gkSPsG66g1KXzzOeI9J/HFoIW9O7oFn1bY8FVeZ8sX9HF2tiBRAGmcrIiKZl3IJfn4f65pxtsELW6wVeMvSk/A6sQxsVYGSgd4OLlJEnJ3TDE1wBIVZEZFscPkMrJuAdeMk2+CFVZZajDd6Uj+6OY80K08hHw8HFykizkph1g6FWRGRbJSUCD++iXXzDFwMMwALLQ2Y4no3bZveyf2NyuDj4dAVbSLihBRm7VCYFRHJAaf3YqwcDdvmYsLAbLjwhaUZn3n15O5WDeh5Rxjurg5vbS4iTkJh1g6FWRGRHJT4O8bylzDt/gGAK4Y7MyxxfBfQgwfj7qB9jZK4uKhHrYjYpzBrh8KsiEguOLgR69KRuNgGL3jzgbk9G0r0YECb2jSpUEyDF0TkhhRm7VCYFRHJJYYBfy3DsnQkrsd/B+CEEcBEcxf2lO7Gk21qUqd0YQcXKSJ5kcKsHQqzIiK5zGqF7V9hWf4yrmf3A3DIWpy3zd25XLkLT7euSkQJf8fWKCJ5isKsHQqzIiIOYkmFhE+xrHwd14vHANhlDWWspQeBtToxKLYSpQqpR62IKMzapTArIuJgKZfg5w+wrHkb138GL/xijeBt424q12/Lo80jKOKrHrUiBZnCrB0KsyIiecTls7B+ApYNk3A1XwZgtaUm77ncQ+MmrfjfnWXx9VSPWpGCSGHWDoVZEZE8JukYxo9vYmyebhu88K2lAdM87qFTy6bcXa80Hm7qUStSkCjM2qEwKyKSR53eh7Hytf8MXmjKl3730DuuER1rhahHrUgBoTBrh8KsiEged2w71mUv4bJ7MQDJhjszLLEsK3IPj7atR7NKxdWjViSfU5i1Q2FWRMRJHPwprUftofVA2uCFD83t2FrqXga1iyQqvIiDCxSRnKIwa4fCrIiIEzEM+Gs55qUjcLtm8MJ75s4kVribwa1rUClYPWpF8huFWTsUZkVEnNA/gxfMy1/B7ew+AA4bxRhn7g41ezA4tgqhhX0cXKSIZBeFWTsUZkVEnJglFRI+w7zyddwuJgJpgxfescYTVK8rj7eoQFE/TwcXKSK3S2HWDoVZEZF8IPUy/PwB5tVjcUtJG7yQYI1gAndTq0lHHmhcDj/1qBVxWgqzdijMiojkI5fPwvp3sax/D1dL2uCFHy01eN/9Plq2iOPeBqXxdHN1bI0ikmUKs3YozIqI5EO2wQszcDFSAfjWUp+Z3r3oHteczrVL4aoetSJOQ2HWDoVZEZF87Mx+rCtew7TtC9vghbmWpnxbuDf3t2lEyyol1KNWxAkozNqhMCsiUgAc245l2cu47v4eSBu88LEllvUle/Fo2/rUK6setSJ5mcKsHQqzIiIFyKGfMS8Zgds/gxeS/hm88Ff53jzRpjZVSuq/AyJ5kcKsHQqzIiIFjGHAnuWkLhmJ+/FtAJw0AnjP0omkar0ZEFud0kXVo1YkL1GYtUNhVkSkgLJaYcd8Upe+gvu5vUDa4IV3Ld3xrnsPj7WsTHF/9agVyQsUZu1QmBURKeAsqbB1JqnLX8P90jEA/rSW4l16UrZRDx5sWh5/L3cHFylSsCnM2qEwKyIiwD+DFz4kdfVY3FPOArDVWp5JrvdSr0UX7msQjpe7etSKOILCrB0KsyIiks6VcxjrJmBZ/x5u1wxemOHVi9ZxbelauxRuri4OLlKkYFGYtUNhVkREruvCcayr38TYPA1XwwzAd5Z6fBnQl55tWxJbNUg9akVyicKsHQqzIiJi15n9WFaMxmXbHEwYWAwTcy1NWVbifvq1a0zD8kUdXaFIvqcwa4fCrIiIZMqxHaQuewn3awYvfGKJYWv4/3ikbT2qlwp0cIEi+ZfCrB0KsyIikiWHNpHyw4t4HP538MJUc1v+rtqPx+MiKVPM18EFiuQ/CrN2KMyKiEiW/TN4IfmHkXieSBu8cMrwZ5KlC+Y6fXmsVTVKBHg5uEiR/ENh1g6FWRERuWVWK+z8muQlL+F5zeCFSUZ3ikT34sGmlQj0Vo9akdulMGuHwqyIiNw2ixm2ziR5+Wt4XkoEYLe1FJNd7qZSs7vp06isetSK3AaFWTsUZkVEJNukXsb4Z/CCxzWDF6Z69OLO2G50jwpVj1qRW6Awa4fCrIiIZLsr57Cuexfr+om2wQtrLdWY6X8/Hdu0p3X1YPWoFckChVk7FGZFRCTHXDiOefWbmK4ZvLDIUo9vi/6Pe9vH0CiimIMLFHEOCrN2KMyKiEiOO3OA1OWv4fr7F7hgxWKY+NLSlA1hD9CvXRNqhKpHrYg9CrN2KMyKiEiuOb6T5CWj8Pzr6uAFNz6zxPBnhYd4uG09yhX3c3CBInmTwqwdCrMiIpLrDm3iyuIX8fo7bfDCBcOLj6ztOFPzIfrHRhIcqB61ItdSmLVDYVZERBzCMGDPCi4vHoH3yX8HL7xv7YJ7gwd4qHlVAn3Uo1YEFGbtUpgVERGHMgzY8TWXfxiJ9/l9APxtFOV9012UbHI/fe+sgLeHetRKwaYwa4fCrIiI5AkWM8bWmSQvew2vy2mDF/6yhvCh+z3UjOlFjztK464etVJAKczaoTArIiJ5SuoVrD9/SOrqt/C0DV4ox6c+fWjetgdtq5fExUU9aqVgUZi1Q2FWRETypCvnMa+bgLF+Iu7XDF6YV6QfXdp1pHGFYhq8IAWGwqwdCrMiIpKnXThByqo3cdkyDTcjFYDvLXewvORD3NchlsiwQo6tTyQXKMzaoTArIiJO4exBrix9FY/t/w5emGdpQkK5/vRr34SIEupRK/mXwqwdCrMiIuJUjv+R1vlgz7+DF2ZZWnGo+qM82KYeJQO9HVygSPZTmLVDYVZERJzS4c1cWjQcnyP/Dl6YYbTjyh2P0q9FTQr7eji4QJHsozBrh8KsiIg4LcOAvSu5uOhFfE+lDV44bfjxEV3xa/wwfZpUxsfDzcFFitw+hVk7FGZFRMTpGQbGjq+5tHgUvkl7gbTBC9Nce1C25QP0qF8ODzf1qBXnpTBrh8KsiIjkGxYz1q2zSF72Kt7/DF7YYy3JDK9e1G3Thw61SqlHrTglhVk7FGZFRCTfSb2C+eepmFe9iVfqWQB+tZbji4D7iWkfT9NKJdSjVpyKwqwdCrMiIpJvXTlPytp3YcNEPCyXAFhnqcZ3JR6iW8dORIUXdnCBIpmjMGuHwqyIiOR7F09yZcUY3H75d/DCYssdrA/vT68OcVQI8ndwgSL2KczaoTArIiIFxtmDXFryKl47/h28MN/amF2VH6dvuyaUKqQetZI3KczaoTArIiIFzoldXPh+BH57/x288Lm1FSfrPMH9sfUooh61kscozNqhMCsiIgXW4S0kfTcc/6PrALhoePIJ7aHhE/RuXgNfT/WolbwhK3nN4U3oJk2aRNmyZfHy8iIqKoo1a9bccN+vvvqKmJgYihcvTkBAAA0bNuSHH37IxWpFREScWGgU/g8vwui1gKQiNfA1JfOIaR7xG9rzwRuD+fTHP0gxWx1dpUiWODTMzpkzh0GDBjFs2DASEhJo3Lgxbdq04eDBg9fd/8cffyQmJoZFixaxZcsWmjdvTocOHUhISMjlykVERJyXqXxz/J9Yg/WuT0jyK0cR0wUGWz+h5fI2vP3GMBZs2Y/FWqB+cStOzKHLDOrXr0+dOnWYPHmybVuVKlXo3Lkzo0ePztQ5qlWrRnx8PC+++GKm9tcyAxERkWtYzJi3ziZ56Sv4Xvl38MLnfr1p0P5+WlQJVo9ayXVOscwgJSWFLVu2EBsbm257bGws69evz9Q5rFYrSUlJFClS5Ib7JCcnc/78+XQvERER+YerG25RvfB96ldSWr3KZfdClHc5yrBLb1D88za8MmEim/edcnSVIjfksDB78uRJLBYLQUFB6bYHBQWRmJiYqXOMHTuWixcv0qNHjxvuM3r0aAIDA22vsLCw26pbREQkX3L3wuPOx/F+ahuXGz1LsosPNV32MfzMC6RMa8+r73/CH4l6ICR5j8M/APbfX10YhpGpX2fMnj2bkSNHMmfOHEqUKHHD/YYOHcq5c+dsr0OHDt12zSIiIvmWVwDeMcPwfGobF+s8jNnkTrTrDoYdfYID73XhjU/mc+j0JUdXKWLjsDBbrFgxXF1dMzyFPX78eIantf81Z84c+vXrxxdffEGrVq3s7uvp6UlAQEC6l4iIiNyEbzF8O47BbWAC56v0xIoLca6beWbP/Wwa34Pxc5dx8kKyo6sUcVyY9fDwICoqiqVLl6bbvnTpUqKjo2943OzZs+nbty+zZs2iXbt2OV2miIhIwVYojID493F5bCNny7TBxWTQ1WUNj/7eg8Vv9ub97zaQdCXV0VVKAebQbgZz5syhV69eTJkyhYYNG/LBBx/w4Ycfsn37dsLDwxk6dCh///03n3zyCZAWZHv37s0777xD165dbefx9vYmMDAwU9dUNwMREZHb8PcWziwcTuHEfwcvzHJpj2fTQcTfWQ1PN1cHFyj5gVNNAJs0aRJjxozh6NGjVK9enXHjxtGkSRMA+vbty/79+1m1ahUAzZo1Y/Xq1RnO0adPH2bMmJGp6ynMioiI3D5jzyrOffsChc5sA+CM4cdM926ExA6gU93yuLqonZfcOqcKs7lNYVZERCSbGAaWHQu58P0IAi/sBeCoUYTPfe6mRrvHaFktRD1q5ZYozNqhMCsiIpLNrBZSf5nFlaWv4J/87+CF+YX60LjTA9QvX9zBBYqzUZi1Q2FWREQkh5iTubzhQ4zVb+JjPgvA79YyLA5+iLad7qNqqcx9vkVEYdYOhVkREZEclpzEhVUTcPtpIl7WtJ60GyxV2VDuMbp37Erpoj4OLlDyOoVZOxRmRUREcsnFU5xb+gY+v07D3Uhr37XUWpddVQfSo10sJfy9HFyg5FUKs3YozIqIiOSyc4c5vehlCu36AhesWA0TC407OR71JPFxjQnwcnd0hZLHKMzaoTArIiLiICf+5OTCFyl28HsAUgxX5plisNz5NN2b1sHLXT1qJY3CrB0KsyIiIo5l/P0Lp75+gWLH/x288IVbBwq1fIoO9Svj5uqwAaWSRyjM2qEwKyIikjdY/lrF2W9foOjZfwcvfOHVjbJtBxNTs4x61BZgCrN2KMyKiIjkIYZByvaFXPx+BIUv/jt44Sv/e6nT6TEaVijp4ALFERRm7VCYFRERyYOsFi5vmUXKslcJTD4KwF5rMN8X70fTLg9SPbSwgwuU3KQwa4fCrIiISB5mTubCug9hzZv4XTN4YXXYI7TrfB9livs5tj7JFQqzdijMioiIOIHkJM6ueAevTe/ZBi/8ZK1CQsWBdOnYhaAA9ajNzxRm7VCYFRERcSIXT3Hqh9cJ+G067qQNXlhuRLG/1lN0bxNLoLd61OZHCrN2KMyKiIg4oXOHOb7wJYr+NRfXfwYvLDLdybkGz9Ct5Z3qUZvPKMzaoTArIiLivIwTf3Ls6xcJPvzv4IWvXWNwaz6EDtGR6lGbTyjM2qEwKyIi4vwshxM4+fXzBJ1YD8Alw5OvPDpQovWzxNSpqB61Tk5h1g6FWRERkfwj5a9VnP3mBUqcTxu8cNbwZYFvDyp2eIroKmEOrk5ulcKsHQqzIiIi+YxhcHnbN1z6fgRFL+8DINEozKLCvajbdQA1Sxd3cIGSVQqzdijMioiI5FNWC0mbZmJe/hqFU9IGL+yzBrEi5EGadX2Y8iX0331noTBrh8KsiIhIPmdO5syaD3Bb+xb+lrMAbLeG83O5x2nTuRfBhbwdW5/clMKsHQqzIiIiBUTyBU4sG4/v5vfwMdIGL/xsVOGPaoPp2L4LhXw8HFyg3IjCrB0KsyIiIgXMpdMkfvcaRbZ/jAcpAKyiDolRz9IxLgYfDzcHFyj/pTBrh8KsiIhIwWScO8yRr0cRvPdL2+CFH1wak9z4Odo1bYi7etTmGQqzdijMioiIFGzWE7s5Mv8FQo8sBiDVcOVb91h8Y4bS6o6auLioR62jKczaoTArIiIiAKmHEji+4HlKnfp38MJC746Uaj+URtXKafCCAynM2qEwKyIiIte6/Ocqzi58gZJJ/w5eWBQQT9UuzxBZLsTB1RVMCrN2KMyKiIhIBoZB0m8Lubx4BCUu7wXgmFGIZcX7Ur/bQCJKFnFwgQWLwqwdCrMiIiJyQ1YLp3+aCStepUhqIgD7jSDWhz1Ms279CSns6+ACCwaFWTsUZkVEROSmzMkcX/U+XhvGEvDP4IWdRji/VhxAXKdeFPbzdGx9+ZzCrB0KsyIiIpJpyRc48sM4CiVMsg1e2GJUYV+tp2jTrgu+nupRmxMUZu1QmBUREZGsMi6e4tDC1wj64xM8/xm8sMYUxZmGz9G6RSs83NSjNjspzNqhMCsiIiK3ynr2bw4uGEHo/nm4/TN4YZlbY2j+PK2iG6hHbTZRmLVDYVZERERuV8rx3Rz56gXKJP47eGGxZyxF2rxAdGQ19ai9TQqzdijMioiISHa5fPAXjs8fRviZtMELlw0PFvt1pmyn54msWNbB1TkvhVk7FGZFREQkuyX9sZJz3w4n9ELa4IVzhg/LitxDja5DqBhWwsHVOR+FWTsUZkVERCRHGAanE74h5YeRBCf/O3hhTcn/0aD7IEKLBTq4QOehMGuHwqyIiIjkKKuFxHWf4bb6NYqZ0wYvHDRKsLncozTt2p+i/t4OLjDvU5i1Q2FWREREcoU5hcPLJ+P30zgKWc8AsMsozc5qg2nVsRd+Xu4OLjDvUpi1Q2FWREREcpORfIEDi8ZS7Lf38TMuApBAZY7UHUKr1p3wdHN1cIV5j8KsHQqzIiIi4gjWi6fZ9/WrhP757+CF9S5RXG78PM2atsRVPWptFGbtUJgVERERR0o9c5j9X42k7KG0wQsAK92b4NFqONH17lCPWhRm7VKYFRERkbzgSuKfHPrqBSoc/wFIG7ywwieOoA4vElm1ioOrcyyFWTsUZkVERCQvSdq3heNfD6P82Q1A2uCFlYFdKN/1BSqVKe3g6hxDYdYOhVkRERHJi07vWEnSt8MJv/Tv4IU1Je4lsvtzhAYVc3B1uUth1g6FWREREcmzDIPEzQuwLH2JUilpgxeOG4XYVLof9boNpnghfwcXmDsUZu1QmBUREZE8z2rl0I+f4LlmNCUsVwcvBPF7xcdo3LU//t6eDi4wZynM2qEwKyIiIk7DnMLeHyZRePM4ChtnAfiTcPbVepKm7e7Dy8PNsfXlEIVZOxRmRURExNkYyRfYvfAtQn7/AD/SBi/8aqrM6QZDaRLTKd/1qFWYtUNhVkRERJyV+cIpds9/hbJ7PsPrn8ELP7tFYW4+nIbRzfJNj1qFWTsUZkVERMTZXTl9mL3zRlDh7/m4YwFgjWdT/NqMoHZklIOru30Ks3YozIqIiEh+kXRkF4fmvUDVU0uAtMELa/xbU6rTCCpVqOTg6m6dwqwdCrMiIiKS35z+azMnvnmBSuf/Hbywrmg3KnV7gbBSoQ6uLusUZu1QmBUREZH8KvG3FVz8fjjlL/8OwHnDh59C7qPWXc9RokhRB1eXeQqzdijMioiISL5mGBz4aT6m5S9TOjVt8MIJI5Bfyz1Ive5PEuDr6+ACb05h1g6FWRERESkQrFZ2r5iB//o3CLamDV44TAn+rPoE0Z364+Xp4eACb0xh1g6FWRERESlIDHMyOxe9R1DCBIoaZwD4yxTO0ainadj6XtzcXB1cYUYKs3YozIqIiEhBZLlyge0L3qTMHx8S8M/ghd9dKnPhzmHUb94hT/WoVZi1Q2FWRERECrIr50/xx7yXqXRgJt7/DF7Y4h6FW8wIatVr6uDq0ijM2qEwKyIiIgIXTh7iry9HUO3oAtxNaYMXNno3pXD7l6hULdKhtWUlr7nkUk03NGnSJMqWLYuXlxdRUVGsWbPG7v6rV68mKioKLy8vypUrx5QpU3KpUhEREZH8w69YGJH9p3H+gfX8VjgWq2GiweXVlP+iOWvH3cuBfbsdXWKmODTMzpkzh0GDBjFs2DASEhJo3Lgxbdq04eDBg9fdf9++fbRt25bGjRuTkJDA888/z4ABA5g3b14uVy4iIiKSPxQNq0zNgXM5fs9Stvs1xM1k5c5z3xI0oyE/vvcIx48ddXSJdjl0mUH9+vWpU6cOkydPtm2rUqUKnTt3ZvTo0Rn2HzJkCN988w07d+60bevfvz+//vorGzZsyNQ1tcxARERE5Mb2/7KMlB9GUDH538ELCWG9iez+HIGFCudKDU6xzCAlJYUtW7YQGxubbntsbCzr16+/7jEbNmzIsH9cXBybN28mNTX1usckJydz/vz5dC8RERERub4ydVpR8bm17Go5jX1u5QgwXaLp4SmYx9fil6WzHV1eBg4LsydPnsRisRAUFJRue1BQEImJidc9JjEx8br7m81mTp48ed1jRo8eTWBgoO0VFhaWPd+AiIiISH5lMlGpcTfKPL+ZbQ3e5ohLSYpyjqIhZR1dWQYO/wDYf3uaGYZht8/Z9fa/3varhg4dyrlz52yvQ4cO3WbFIiIiIgWDycWVGq37ETT0N/6M/YTwag0cXVIGbo66cLFixXB1dc3wFPb48eMZnr5eFRwcfN393dzcKFq06HWP8fT0xNPTM3uKFhERESmAXN09qBjdydFlXJfDnsx6eHgQFRXF0qVL021funQp0dHR1z2mYcOGGfZfsmQJdevWxd3dPcdqFREREZG8yaHLDJ588kmmTp3KtGnT2LlzJ4MHD+bgwYP0798fSFsi0Lt3b9v+/fv358CBAzz55JPs3LmTadOm8dFHH/H000876lsQEREREQdy2DIDgPj4eE6dOsVLL73E0aNHqV69OosWLSI8PByAo0ePpus5W7ZsWRYtWsTgwYN57733CAkJYcKECXTr1s1R34KIiIiIOJDG2YqIiIhInuIUfWZFRERERG6XwqyIiIiIOC2FWRERERFxWgqzIiIiIuK0FGZFRERExGkpzIqIiIiI01KYFRERERGnpTArIiIiIk5LYVZEREREnJbCrIiIiIg4LTdHF5Dbrk7vPX/+vIMrEREREZHruZrTruY2ewpcmE1KSgIgLCzMwZWIiIiIiD1JSUkEBgba3cdkZCby5iNWq5UjR47g7++PyWTKlWueP3+esLAwDh06REBAQK5cUxxD97rg0L0uOHSvCxbd77zBMAySkpIICQnBxcX+qtgC92TWxcWF0NBQh1w7ICBA/8coIHSvCw7d64JD97pg0f12vJs9kb1KHwATEREREaelMCsiIiIiTkthNhd4enoyYsQIPD09HV2K5DDd64JD97rg0L0uWHS/nU+B+wCYiIiIiOQfejIrIiIiIk5LYVZEREREnJbCrIiIiIg4LYVZEREREXFaCrPZYNKkSZQtWxYvLy+ioqJYs2aN3f1Xr15NVFQUXl5elCtXjilTpuRSpZIdsnK/jx49yj333EOlSpVwcXFh0KBBuVeo3Las3OuvvvqKmJgYihcvTkBAAA0bNuSHH37IxWrldmTlXq9du5ZGjRpRtGhRvL29qVy5MuPGjcvFauV2ZfW/21etW7cONzc3IiMjc7ZAyRKF2ds0Z84cBg0axLBhw0hISKBx48a0adOGgwcPXnf/ffv20bZtWxo3bkxCQgLPP/88AwYMYN68eblcudyKrN7v5ORkihcvzrBhw6hVq1YuVyu3I6v3+scffyQmJoZFixaxZcsWmjdvTocOHUhISMjlyiWrsnqvfX19efzxx/nxxx/ZuXMnL7zwAi+88AIffPBBLlcutyKr9/uqc+fO0bt3b1q2bJlLlUpmqTXXbapfvz516tRh8uTJtm1VqlShc+fOjB49OsP+Q4YM4ZtvvmHnzp22bf379+fXX39lw4YNuVKz3Lqs3u9rNWvWjMjISMaPH5/DVUp2uJ17fVW1atWIj4/nxRdfzKkyJRtkx73u2rUrvr6+fPrppzlVpmSTW73fPXv2pEKFCri6urJgwQK2bt2aC9VKZujJ7G1ISUlhy5YtxMbGptseGxvL+vXrr3vMhg0bMuwfFxfH5s2bSU1NzbFa5fbdyv0W55Qd99pqtZKUlESRIkVyokTJJtlxrxMSEli/fj1NmzbNiRIlG93q/Z4+fTp79uxhxIgROV2i3AI3RxfgzE6ePInFYiEoKCjd9qCgIBITE697TGJi4nX3N5vNnDx5kpIlS+ZYvXJ7buV+i3PKjns9duxYLl68SI8ePXKiRMkmt3OvQ0NDOXHiBGazmZEjR/LAAw/kZKmSDW7lfu/evZvnnnuONWvW4Oam2JQX6a5kA5PJlO5rwzAybLvZ/tfbLnlTVu+3OK9bvdezZ89m5MiRfP3115QoUSKnypNsdCv3es2aNVy4cIGNGzfy3HPPERERwd13352TZUo2yez9tlgs3HPPPYwaNYqKFSvmVnmSRQqzt6FYsWK4urpm+Nvc8ePHM/yt76rg4ODr7u/m5kbRokVzrFa5fbdyv8U53c69njNnDv369WPu3Lm0atUqJ8uUbHA797ps2bIA1KhRg2PHjjFy5EiF2Twuq/c7KSmJzZs3k5CQwOOPPw6kLSEyDAM3NzeWLFlCixYtcqV2uTGtmb0NHh4eREVFsXTp0nTbly5dSnR09HWPadiwYYb9lyxZQt26dXF3d8+xWuX23cr9Fud0q/d69uzZ9O3bl1mzZtGuXbucLlOyQXb9/9owDJKTk7O7PMlmWb3fAQEBbNu2ja1bt9pe/fv3p1KlSmzdupX69evnVulijyG35fPPPzfc3d2Njz76yNixY4cxaNAgw9fX19i/f79hGIbx3HPPGb169bLtv3fvXsPHx8cYPHiwsWPHDuOjjz4y3N3djS+//NJR34JkQVbvt2EYRkJCgpGQkGBERUUZ99xzj5GQkGBs377dEeVLFmT1Xs+aNctwc3Mz3nvvPePo0aO219mzZx31LUgmZfVeT5w40fjmm2+MP//80/jzzz+NadOmGQEBAcawYcMc9S1IFtzKv8evNWLECKNWrVq5VK1khsJsNnjvvfeM8PBww8PDw6hTp46xevVq23t9+vQxmjZtmm7/VatWGbVr1zY8PDyMMmXKGJMnT87liuV2ZPV+Axle4eHhuVu03JKs3OumTZte91736dMn9wuXLMvKvZ4wYYJRrVo1w8fHxwgICDBq165tTJo0ybBYLA6oXG5FVv89fi2F2bxHfWZFRERExGlpzayIiIiIOC2FWRERERFxWgqzIiIiIuK0FGZFRERExGkpzIqIiIiI01KYFRERERGnpTArIiIiIk5LYVZEREREnJbCrIhIPmYymViwYEGm91+1ahUmk4mzZ8/mWE0iItlJYVZEREREnJbCrIiIiIg4LYVZEZHbZLVaeeONN4iIiMDT05PSpUvz6quvAnD48GF69uxJkSJF8PX1pW7duvz0008AjBw5ksjISN5//33CwsLw8fHhrrvuyvSv+Ddt2kRMTAzFihUjMDCQpk2b8ssvv9xw//3792Mymfj888+Jjo7Gy8uLatWqsWrVqgz7btmyhbp16+Lj40N0dDS7du2yvbdnzx46depEUFAQfn5+3HHHHSxbtizzPzARkWykMCsicpuGDh3KG2+8wfDhw9mxYwezZs0iKCiICxcu0LRpU44cOcI333zDr7/+yrPPPovVarUd+9dff/HFF1+wcOFCFi9ezNatW3nssccydd2kpCT69OnDmjVr2LhxIxUqVKBt27YkJSXZPe6ZZ57hqaeeIiEhgejoaDp27MipU6fS7TNs2DDGjh3L5s2bcXNz43//+5/tvQsXLtC2bVuWLVtGQkICcXFxdOjQgYMHD2bhpyYikk0MERG5ZefPnzc8PT2NDz/8MMN777//vuHv72+cOnXquseOGDHCcHV1NQ4dOmTb9v333xsuLi7G0aNHs1yL2Ww2/P39jYULF9q2Acb8+fMNwzCMffv2GYDx+uuv295PTU01QkNDjTfeeMMwDMNYuXKlARjLli2z7fPdd98ZgHH58uUbXrtq1arGu+++m+WaRURul57Miojchp07d5KcnEzLli0zvLd161Zq165NkSJFbnh86dKlCQ0NtX3dsGFDrFZrul/r38jx48fp378/FStWJDAwkMDAQC5cuHDTJ6QNGza0/dnNzY26deuyc+fOdPvUrFnT9ueSJUvargdw8eJFnn32WapWrUqhQoXw8/Pjjz/+0JNZEXEIN0cXICLizLy9vW/pvRsxmUzp/teevn37cuLECcaPH094eDienp40bNiQlJSUW77uVe7u7hneu7o84plnnuGHH37grbfeIiIiAm9vb7p3735L1xURuV16MisichsqVKiAt7c3y5cvz/BezZo12bp1K6dPn77h8QcPHuTIkSO2rzds2ICLiwsVK1a86bXXrFnDgAEDaNu2LdWqVcPT05OTJ0/e9LiNGzfa/mw2m9myZQuVK1e+6XHXXrdv37506dKFGjVqEBwczP79+zN9vIhIdtKTWRGR2+Dl5cWQIUN49tln8fDwoFGjRpw4cYLt27fTq1cvXnvtNTp37szo0aMpWbIkCQkJhISE2H7V7+XlRZ8+fXjrrbc4f/48AwYMoEePHgQHB9/02hEREXz66afUrVuX8+fP88wzz2TqafB7771HhQoVqFKlCuPGjePMmTPpPuCVmet+9dVXdOjQAZPJxPDhw9N9qE1EJDfpyayIyG0aPnw4Tz31FC+++CJVqlQhPj6e48eP4+HhwZIlSyhRogRt27alRo0avP7667i6utqOjYiIoGvXrrRt25bY2FiqV6/OpEmTMnXdadOmcebMGWrXrk2vXr0YMGAAJUqUuOlxr7/+Om+88Qa1atVizZo1fP311xQrVizT3++4ceMoXLgw0dHRdOjQgbi4OOrUqZPp40VEspPJMAzD0UWIiBREI0eOZMGCBWzdujVXrrd//37Kli1LQkICkZGRuXJNEZGcpiezIiIiIuK0FGZFRPIoPz+/G77WrFnj6PJERPIELTMQEcmj/vrrrxu+V6pUqVtq/SUikt8ozIqIiIiI09IyAxERERFxWgqzIiIiIuK0FGZFRERExGkpzIqIiIiI01KYFRERERGnpTArIiIiIk5LYVZEREREnNb/AdE6fjArq8muAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scores = [t.score(X_train, y_train) for t in trees]\n",
    "val_scores = [t.score(X_val, y_val) for t in trees]\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(ccp_alphas, train_scores, label=\"Train R²\")\n",
    "plt.plot(ccp_alphas, val_scores, label=\"Validation R²\")\n",
    "plt.xlabel(\"ccp_alpha\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.legend()\n",
    "plt.title(\"Cost-Complexity Pruning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ec56e-184c-46e2-8e31-a9e18ac5a49b",
   "metadata": {},
   "source": [
    "# Custom Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432945a7-3dc2-41e5-a5d3-b5a49a0117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def entropy(y):\n",
    "    counts = Counter(y)\n",
    "    n = len(y)\n",
    "    return -sum((c/n) * np.log2(c/n) for c in counts.values())\n",
    "\n",
    "\n",
    "def mse(y):\n",
    "    mean = np.mean(y)\n",
    "    return np.mean((y - mean) ** 2)\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, *, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value  # prediction at leaf\n",
    "\n",
    "class BaseDecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, verbose=True):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.verbose = verbose\n",
    "        self.root = None\n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -np.inf\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        parent_impurity = self._impurity(y)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        for feature in range(n_features):\n",
    "            values = X[:, feature]\n",
    "\n",
    "            # Check if feature is categorical\n",
    "            is_categorical = isinstance(values[0], str)\n",
    "\n",
    "            if is_categorical:\n",
    "                categories = set(values)\n",
    "                for cat in categories:\n",
    "                    left_idx = values == cat\n",
    "                    right_idx = values != cat\n",
    "                    gain = self._information_gain(y, left_idx, right_idx, parent_impurity)\n",
    "\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_threshold = cat\n",
    "\n",
    "            else:\n",
    "                unique_vals = np.unique(values)\n",
    "                thresholds = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
    "\n",
    "                for t in thresholds:\n",
    "                    left_idx = values <= t\n",
    "                    right_idx = values > t\n",
    "                    gain = self._information_gain(y, left_idx, right_idx, parent_impurity)\n",
    "\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_threshold = t\n",
    "\n",
    "        return best_feature, best_threshold, best_gain\n",
    "    def _information_gain(self, y, left_idx, right_idx, parent_impurity):\n",
    "        n = len(y)\n",
    "        n_l, n_r = np.sum(left_idx), np.sum(right_idx)\n",
    "\n",
    "        if n_l == 0 or n_r == 0:\n",
    "            return 0\n",
    "\n",
    "        child_impurity = (\n",
    "            (n_l / n) * self._impurity(y[left_idx]) +\n",
    "            (n_r / n) * self._impurity(y[right_idx])\n",
    "        )\n",
    "\n",
    "        return parent_impurity - child_impurity\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        if self.verbose:\n",
    "            print(f\"\\nDepth {depth} | Samples {len(y)}\")\n",
    "\n",
    "        # Stopping conditions\n",
    "        if (depth >= self.max_depth or\n",
    "            len(y) < self.min_samples_split or\n",
    "            self._is_pure(y)):\n",
    "\n",
    "            value = self._leaf_value(y)\n",
    "            if self.verbose:\n",
    "                print(f\"Leaf created with value: {value}\")\n",
    "            return TreeNode(value=value)\n",
    "\n",
    "        feature, threshold, gain = self._best_split(X, y)\n",
    "\n",
    "        if gain <= 0:\n",
    "            value = self._leaf_value(y)\n",
    "            if self.verbose:\n",
    "                print(f\"No gain → Leaf with value: {value}\")\n",
    "            return TreeNode(value=value)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Split: Feature {feature}, Threshold {threshold}, Gain {gain:.4f}\")\n",
    "\n",
    "        if isinstance(threshold, str):\n",
    "            left_idx = X[:, feature] == threshold\n",
    "        else:\n",
    "            left_idx = X[:, feature] <= threshold\n",
    "\n",
    "        right_idx = ~left_idx\n",
    "\n",
    "        left = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
    "        right = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "\n",
    "        return TreeNode(feature=feature, threshold=threshold, left=left, right=right)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _predict_one(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        if isinstance(node.threshold, str):\n",
    "            if x[node.feature] == node.threshold:\n",
    "                return self._predict_one(x, node.left)\n",
    "            else:\n",
    "                return self._predict_one(x, node.right)\n",
    "        else:\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                return self._predict_one(x, node.left)\n",
    "            else:\n",
    "                return self._predict_one(x, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.root) for x in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86426f1e-5851-4bd7-8871-985b43d981a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(BaseDecisionTree):\n",
    "    def _impurity(self, y):\n",
    "        return entropy(y)\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        return Counter(y).most_common(1)[0][0]\n",
    "\n",
    "    def _is_pure(self, y):\n",
    "        return len(set(y)) == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8371cb0e-bd48-4dad-8106-14764e191d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor(BaseDecisionTree):\n",
    "    def _impurity(self, y):\n",
    "        return mse(y)\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        return np.mean(y)\n",
    "\n",
    "    def _is_pure(self, y):\n",
    "        return np.var(y) == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba00615-5f60-4dfe-8987-e6196bb17b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Depth 0 | Samples 5\n",
      "Split: Feature 0, Threshold 5.5, Gain 0.9710\n",
      "\n",
      "Depth 1 | Samples 2\n",
      "Leaf created with value: 0\n",
      "\n",
      "Depth 1 | Samples 3\n",
      "Leaf created with value: 1\n",
      "[0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [5.1, \"red\"],\n",
    "    [4.9, \"blue\"],\n",
    "    [6.2, \"red\"],\n",
    "    [5.9, \"green\"],\n",
    "    [6.0, \"blue\"]\n",
    "], dtype=object)\n",
    "\n",
    "y = np.array([0, 0, 1, 1, 1])\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=3, verbose=True)\n",
    "tree.fit(X, y)\n",
    "\n",
    "preds = tree.predict(X)\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a678d-651d-4fe6-b7af-d805ca045572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b2e9eb-4459-4c3e-b3ba-d58c1227e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def entropy(y):\n",
    "    counts = Counter(y)\n",
    "    n = len(y)\n",
    "    return -sum((c / n) * math.log2(c / n) for c in counts.values())\n",
    "\n",
    "def gini(y):\n",
    "    counts = Counter(y)\n",
    "    n = len(y)\n",
    "    return 1 - sum((c / n) ** 2 for c in counts.values())\n",
    "\n",
    "def mse(y):\n",
    "    mean = np.mean(y)\n",
    "    return np.mean((y - mean) ** 2)\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, *, feature=None, threshold=None, left=None, right=None,\n",
    "                 value=None, impurity=None, n_samples=None, gain=0.0):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.impurity = impurity\n",
    "        self.n_samples = n_samples\n",
    "        self.gain = gain\n",
    "\n",
    "class BaseDecisionTree:\n",
    "    def __init__(self, max_depth=10, min_samples_split=2,\n",
    "                 criterion=\"gini\", task=\"classification\", verbose=True):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.task = task\n",
    "        self.verbose = verbose\n",
    "        self.root = None\n",
    "        self.feature_importances_ = defaultdict(float)\n",
    "\n",
    "        if task == \"classification\":\n",
    "            self._impurity = entropy if criterion == \"entropy\" else gini\n",
    "        else:\n",
    "            self._impurity = mse\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.root = self._grow_tree(X, y, depth=0)\n",
    "        total_gain = sum(self.feature_importances_.values())\n",
    "        if total_gain > 0:\n",
    "            for k in self.feature_importances_:\n",
    "                self.feature_importances_[k] /= total_gain\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -1\n",
    "        best_feature, best_threshold, best_splits = None, None, None\n",
    "        parent_impurity = self._impurity(y)\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            values = X[:, feature]\n",
    "            unique_vals = np.unique(values)\n",
    "\n",
    "            if values.dtype.kind in {\"U\", \"S\", \"O\"}:\n",
    "                for v in unique_vals:\n",
    "                    left_idx = values == v\n",
    "                    right_idx = ~left_idx\n",
    "                    gain = self._information_gain(y, left_idx, right_idx, parent_impurity)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_threshold = v\n",
    "                        best_splits = (left_idx, right_idx)\n",
    "            else:\n",
    "                sorted_vals = np.sort(unique_vals.astype(float))\n",
    "                thresholds = (sorted_vals[:-1] + sorted_vals[1:]) / 2\n",
    "                for t in thresholds:\n",
    "                    left_idx = values.astype(float) <= t\n",
    "                    right_idx = values.astype(float) > t\n",
    "                    gain = self._information_gain(y, left_idx, right_idx, parent_impurity)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain = gain\n",
    "                        best_feature = feature\n",
    "                        best_threshold = t\n",
    "                        best_splits = (left_idx, right_idx)\n",
    "\n",
    "        return best_feature, best_threshold, best_splits, best_gain\n",
    "\n",
    "    def _information_gain(self, y, left_idx, right_idx, parent_impurity):\n",
    "        n = len(y)\n",
    "        n_l, n_r = np.sum(left_idx), np.sum(right_idx)\n",
    "        if n_l == 0 or n_r == 0:\n",
    "            return 0\n",
    "        child_impurity = (\n",
    "            (n_l / n) * self._impurity(y[left_idx]) +\n",
    "            (n_r / n) * self._impurity(y[right_idx])\n",
    "        )\n",
    "        return parent_impurity - child_impurity\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        node = TreeNode(\n",
    "            impurity=self._impurity(y),\n",
    "            n_samples=len(y),\n",
    "            value=self._leaf_value(y)\n",
    "        )\n",
    "\n",
    "        if depth >= self.max_depth or len(y) < self.min_samples_split:\n",
    "            return node\n",
    "\n",
    "        feature, threshold, splits, gain = self._best_split(X, y)\n",
    "\n",
    "        if feature is None or gain <= 0:\n",
    "            return node\n",
    "\n",
    "        left_idx, right_idx = splits\n",
    "        self.feature_importances_[feature] += gain * len(y)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Depth {depth} | Split: X[{feature}] <= {threshold} | Gain: {gain:.4f}\")\n",
    "\n",
    "        node.feature = feature\n",
    "        node.threshold = threshold\n",
    "        node.gain = gain\n",
    "        node.left = self._grow_tree(X[left_idx], y[left_idx], depth + 1)\n",
    "        node.right = self._grow_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "        node.value = None\n",
    "        return node\n",
    "\n",
    "    def _leaf_value(self, y):\n",
    "        if self.task == \"classification\":\n",
    "            return Counter(y).most_common(1)[0][0]\n",
    "        return np.mean(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_row(x, self.root) for x in X])\n",
    "\n",
    "    def _predict_row(self, x, node):\n",
    "        if node.feature is None:\n",
    "            return node.value\n",
    "        val = x[node.feature]\n",
    "        if isinstance(node.threshold, str):\n",
    "            if val == node.threshold:\n",
    "                return self._predict_row(x, node.left)\n",
    "            else:\n",
    "                return self._predict_row(x, node.right)\n",
    "        else:\n",
    "            if float(val) <= node.threshold:\n",
    "                return self._predict_row(x, node.left)\n",
    "            else:\n",
    "                return self._predict_row(x, node.right)\n",
    "\n",
    "    def cost_complexity_prune(self, alpha):\n",
    "        def prune(node):\n",
    "            if node.left is None or node.right is None:\n",
    "                return node, node.impurity * node.n_samples, 1\n",
    "\n",
    "            left, left_err, left_leaves = prune(node.left)\n",
    "            right, right_err, right_leaves = prune(node.right)\n",
    "\n",
    "            subtree_err = left_err + right_err\n",
    "            leaf_err = node.impurity * node.n_samples\n",
    "\n",
    "            if leaf_err + alpha <= subtree_err:\n",
    "                return TreeNode(\n",
    "                    value=node.value,\n",
    "                    impurity=node.impurity,\n",
    "                    n_samples=node.n_samples\n",
    "                ), leaf_err, 1\n",
    "\n",
    "            node.left, node.right = left, right\n",
    "            return node, subtree_err, left_leaves + right_leaves\n",
    "\n",
    "        self.root, _, _ = prune(self.root)\n",
    "\n",
    "class DecisionTreeClassifier(BaseDecisionTree):\n",
    "    def __init__(self, max_depth=10, min_samples_split=2,\n",
    "                 criterion=\"gini\", verbose=True):\n",
    "        super().__init__(max_depth, min_samples_split,\n",
    "                         criterion, task=\"classification\", verbose=verbose)\n",
    "\n",
    "class DecisionTreeRegressor(BaseDecisionTree):\n",
    "    def __init__(self, max_depth=10, min_samples_split=2, verbose=True):\n",
    "        super().__init__(max_depth, min_samples_split,\n",
    "                         criterion=\"mse\", task=\"regression\", verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9b14d54-ec62-402b-857e-2c4de5dae9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 0 | Split: X[1] <= Green | Gain: 0.3113\n",
      "Depth 1 | Split: X[0] <= 25 | Gain: 0.3167\n",
      "Depth 2 | Split: X[0] <= 30 | Gain: 0.7219\n",
      "\n",
      "Predictions (classification):\n",
      "['No' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'Yes']\n",
      "\n",
      "Feature importances (classification):\n",
      "{1: np.float64(0.31127812445913283), 0: np.float64(0.6887218755408672)}\n",
      "\n",
      "Predictions after pruning:\n",
      "['No' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'Yes']\n",
      "Depth 0 | Split: X[1] <= High | Gain: 64.2222\n",
      "Depth 1 | Split: X[0] <= 5.0 | Gain: 6.2500\n",
      "Depth 1 | Split: X[1] <= Low | Gain: 20.2500\n",
      "Depth 2 | Split: X[0] <= 1.0 | Gain: 1.0000\n",
      "Depth 2 | Split: X[0] <= 3.0 | Gain: 4.0000\n",
      "\n",
      "Predictions (regression):\n",
      "[10. 12. 18. 22. 30. 35.]\n",
      "\n",
      "Feature importances (regression):\n",
      "{1: np.float64(0.9539720422775315), 0: np.float64(0.04602795772246847)}\n",
      "\n",
      "Predictions after pruning:\n",
      "[10. 12. 18. 22. 30. 35.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Classification example\n",
    "# -------------------------------\n",
    "\n",
    "# Mixed dataset: continuous + categorical\n",
    "X_cls = np.array([\n",
    "    [25, \"Red\"],\n",
    "    [30, \"Blue\"],\n",
    "    [45, \"Red\"],\n",
    "    [35, \"Blue\"],\n",
    "    [22, \"Green\"],\n",
    "    [28, \"Green\"],\n",
    "    [40, \"Red\"],\n",
    "    [50, \"Blue\"]\n",
    "], dtype=object)\n",
    "\n",
    "y_cls = np.array([\"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\"])\n",
    "\n",
    "clf = DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    criterion=\"entropy\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "clf.fit(X_cls, y_cls)\n",
    "\n",
    "print(\"\\nPredictions (classification):\")\n",
    "print(clf.predict(X_cls))\n",
    "\n",
    "print(\"\\nFeature importances (classification):\")\n",
    "print(dict(clf.feature_importances_))\n",
    "\n",
    "# Cost-complexity pruning\n",
    "clf.cost_complexity_prune(alpha=0.01)\n",
    "\n",
    "print(\"\\nPredictions after pruning:\")\n",
    "print(clf.predict(X_cls))\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Regression example\n",
    "# -------------------------------\n",
    "\n",
    "# Dataset: continuous + categorical\n",
    "X_reg = np.array([\n",
    "    [1.0, \"Low\"],\n",
    "    [2.0, \"Low\"],\n",
    "    [3.0, \"Medium\"],\n",
    "    [4.0, \"Medium\"],\n",
    "    [5.0, \"High\"],\n",
    "    [6.0, \"High\"]\n",
    "], dtype=object)\n",
    "\n",
    "y_reg = np.array([10, 12, 18, 22, 30, 35], dtype=float)\n",
    "\n",
    "reg = DecisionTreeRegressor(\n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "reg.fit(X_reg, y_reg)\n",
    "\n",
    "print(\"\\nPredictions (regression):\")\n",
    "print(reg.predict(X_reg))\n",
    "\n",
    "print(\"\\nFeature importances (regression):\")\n",
    "print(dict(reg.feature_importances_))\n",
    "\n",
    "# Cost-complexity pruning\n",
    "reg.cost_complexity_prune(alpha=1.0)\n",
    "\n",
    "print(\"\\nPredictions after pruning:\")\n",
    "print(reg.predict(X_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9979482-94da-4d6b-aca1-09ad335c3991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada3b6d-2c91-4e83-8a7c-9de92bff5c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
